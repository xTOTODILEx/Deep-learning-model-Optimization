{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9dfbf0d-bd95-402c-811c-5d52ede0c51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/shufflenetv2_x1-5666bf0f80.pth\" to /root/.cache/torch/hub/checkpoints/shufflenetv2_x1-5666bf0f80.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# Load the pre-trained ShuffleNet V2 model with scale factor x2.0\n",
    "model = models.shufflenet_v2_x1_0(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb6a6f1c-5268-4e7d-a595-52bb05e12339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleNetV2(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (stage2): Sequential(\n",
      "    (0): InvertedResidual(\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
      "        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Conv2d(24, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(24, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=58, bias=False)\n",
      "        (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=58, bias=False)\n",
      "        (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=58, bias=False)\n",
      "        (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(58, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=58, bias=False)\n",
      "        (4): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(58, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (stage3): Sequential(\n",
      "    (0): InvertedResidual(\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv2d(116, 116, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=116, bias=False)\n",
      "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=116, bias=False)\n",
      "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
      "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
      "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
      "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
      "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
      "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
      "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(116, 116, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=116, bias=False)\n",
      "        (4): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(116, 116, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(116, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (stage4): Sequential(\n",
      "    (0): InvertedResidual(\n",
      "      (branch1): Sequential(\n",
      "        (0): Conv2d(232, 232, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=232, bias=False)\n",
      "        (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): ReLU(inplace=True)\n",
      "      )\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=232, bias=False)\n",
      "        (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=232, bias=False)\n",
      "        (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=232, bias=False)\n",
      "        (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (branch1): Sequential()\n",
      "      (branch2): Sequential(\n",
      "        (0): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(232, 232, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=232, bias=False)\n",
      "        (4): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): Conv2d(232, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv5): Sequential(\n",
      "    (0): Conv2d(464, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdfa9f4e-1c87-4fb9-8b47-5fd5904766fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Dogs\n",
      "Inference time: 4.7121 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.models import shufflenet_v2_x1_0\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "# Load the pre-trained ShuffleNet V2 1.0 model\n",
    "model = shufflenet_v2_x1_0(pretrained=True)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Load and preprocess an example image\n",
    "image_path = '1.jpg'\n",
    "input_image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "# Define the image transformation pipeline\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Apply transformations to the input image\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)  # Add a batch dimension\n",
    "\n",
    "# Make the prediction\n",
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    output = model(input_batch)\n",
    "    end_time = time.time()\n",
    "\n",
    "# Get the predicted class index\n",
    "_, predicted_idx = torch.max(output, 1)\n",
    "predicted_class = \"Cats\" if predicted_idx.item() == 0 else \"Dogs\"\n",
    "\n",
    "# Print the predicted class label and inference time\n",
    "inference_time = end_time - start_time\n",
    "print(f'Predicted class: {predicted_class}')\n",
    "print(f'Inference time: {inference_time:.4f} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed72115d-cede-4514-ad7e-9831a691fe0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:23: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  channels_per_group = num_channels // groups\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input.1 : Float(1, 3, 224, 224, strides=[150528, 50176, 224, 1], requires_grad=0, device=cpu),\n",
      "      %fc.weight : Float(1000, 1024, strides=[1024, 1], requires_grad=1, device=cpu),\n",
      "      %fc.bias : Float(1000, strides=[1], requires_grad=1, device=cpu),\n",
      "      %854 : Float(24, 3, 3, 3, strides=[27, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %855 : Float(24, strides=[1], requires_grad=0, device=cpu),\n",
      "      %857 : Float(24, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %858 : Float(24, strides=[1], requires_grad=0, device=cpu),\n",
      "      %860 : Float(58, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %861 : Float(58, strides=[1], requires_grad=0, device=cpu),\n",
      "      %863 : Float(58, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %864 : Float(58, strides=[1], requires_grad=0, device=cpu),\n",
      "      %866 : Float(58, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %867 : Float(58, strides=[1], requires_grad=0, device=cpu),\n",
      "      %869 : Float(58, 58, 1, 1, strides=[58, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %870 : Float(58, strides=[1], requires_grad=0, device=cpu),\n",
      "      %872 : Float(58, 58, 1, 1, strides=[58, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %873 : Float(58, strides=[1], requires_grad=0, device=cpu),\n",
      "      %875 : Float(58, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %876 : Float(58, strides=[1], requires_grad=0, device=cpu),\n",
      "      %878 : Float(58, 58, 1, 1, strides=[58, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %879 : Float(58, strides=[1], requires_grad=0, device=cpu),\n",
      "      %881 : Float(58, 58, 1, 1, strides=[58, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %882 : Float(58, strides=[1], requires_grad=0, device=cpu),\n",
      "      %884 : Float(58, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %885 : Float(58, strides=[1], requires_grad=0, device=cpu),\n",
      "      %887 : Float(58, 58, 1, 1, strides=[58, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %888 : Float(58, strides=[1], requires_grad=0, device=cpu),\n",
      "      %890 : Float(58, 58, 1, 1, strides=[58, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %891 : Float(58, strides=[1], requires_grad=0, device=cpu),\n",
      "      %893 : Float(58, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %894 : Float(58, strides=[1], requires_grad=0, device=cpu),\n",
      "      %896 : Float(58, 58, 1, 1, strides=[58, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %897 : Float(58, strides=[1], requires_grad=0, device=cpu),\n",
      "      %899 : Float(116, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %900 : Float(116, strides=[1], requires_grad=0, device=cpu),\n",
      "      %902 : Float(116, 116, 1, 1, strides=[116, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %903 : Float(116, strides=[1], requires_grad=0, device=cpu),\n",
      "      %905 : Float(116, 116, 1, 1, strides=[116, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %906 : Float(116, strides=[1], requires_grad=0, device=cpu),\n",
      "      %908 : Float(116, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %909 : Float(116, strides=[1], requires_grad=0, device=cpu),\n",
      "      %911 : Float(116, 116, 1, 1, strides=[116, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %912 : Float(116, strides=[1], requires_grad=0, device=cpu),\n",
      "      %914 : Float(116, 116, 1, 1, strides=[116, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %915 : Float(116, strides=[1], requires_grad=0, device=cpu),\n",
      "      %917 : Float(116, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %918 : Float(116, strides=[1], requires_grad=0, device=cpu),\n",
      "      %920 : Float(116, 116, 1, 1, strides=[116, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %921 : Float(116, strides=[1], requires_grad=0, device=cpu),\n",
      "      %923 : Float(116, 116, 1, 1, strides=[116, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %924 : Float(116, strides=[1], requires_grad=0, device=cpu),\n",
      "      %926 : Float(116, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %927 : Float(116, strides=[1], requires_grad=0, device=cpu),\n",
      "      %929 : Float(116, 116, 1, 1, strides=[116, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %930 : Float(116, strides=[1], requires_grad=0, device=cpu),\n",
      "      %932 : Float(116, 116, 1, 1, strides=[116, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %933 : Float(116, strides=[1], requires_grad=0, device=cpu),\n",
      "      %935 : Float(116, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %936 : Float(116, strides=[1], requires_grad=0, device=cpu),\n",
      "      %938 : Float(116, 116, 1, 1, strides=[116, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %939 : Float(116, strides=[1], requires_grad=0, device=cpu),\n",
      "      %941 : Float(116, 116, 1, 1, strides=[116, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %942 : Float(116, strides=[1], requires_grad=0, device=cpu),\n",
      "      %944 : Float(116, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %945 : Float(116, strides=[1], requires_grad=0, device=cpu),\n",
      "      %947 : Float(116, 116, 1, 1, strides=[116, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %948 : Float(116, strides=[1], requires_grad=0, device=cpu),\n",
      "      %950 : Float(116, 116, 1, 1, strides=[116, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %951 : Float(116, strides=[1], requires_grad=0, device=cpu),\n",
      "      %953 : Float(116, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %954 : Float(116, strides=[1], requires_grad=0, device=cpu),\n",
      "      %956 : Float(116, 116, 1, 1, strides=[116, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %957 : Float(116, strides=[1], requires_grad=0, device=cpu),\n",
      "      %959 : Float(116, 116, 1, 1, strides=[116, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %960 : Float(116, strides=[1], requires_grad=0, device=cpu),\n",
      "      %962 : Float(116, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %963 : Float(116, strides=[1], requires_grad=0, device=cpu),\n",
      "      %965 : Float(116, 116, 1, 1, strides=[116, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %966 : Float(116, strides=[1], requires_grad=0, device=cpu),\n",
      "      %968 : Float(116, 116, 1, 1, strides=[116, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %969 : Float(116, strides=[1], requires_grad=0, device=cpu),\n",
      "      %971 : Float(116, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %972 : Float(116, strides=[1], requires_grad=0, device=cpu),\n",
      "      %974 : Float(116, 116, 1, 1, strides=[116, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %975 : Float(116, strides=[1], requires_grad=0, device=cpu),\n",
      "      %977 : Float(232, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %978 : Float(232, strides=[1], requires_grad=0, device=cpu),\n",
      "      %980 : Float(232, 232, 1, 1, strides=[232, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %981 : Float(232, strides=[1], requires_grad=0, device=cpu),\n",
      "      %983 : Float(232, 232, 1, 1, strides=[232, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %984 : Float(232, strides=[1], requires_grad=0, device=cpu),\n",
      "      %986 : Float(232, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %987 : Float(232, strides=[1], requires_grad=0, device=cpu),\n",
      "      %989 : Float(232, 232, 1, 1, strides=[232, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %990 : Float(232, strides=[1], requires_grad=0, device=cpu),\n",
      "      %992 : Float(232, 232, 1, 1, strides=[232, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %993 : Float(232, strides=[1], requires_grad=0, device=cpu),\n",
      "      %995 : Float(232, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %996 : Float(232, strides=[1], requires_grad=0, device=cpu),\n",
      "      %998 : Float(232, 232, 1, 1, strides=[232, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %999 : Float(232, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1001 : Float(232, 232, 1, 1, strides=[232, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %1002 : Float(232, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1004 : Float(232, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %1005 : Float(232, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1007 : Float(232, 232, 1, 1, strides=[232, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %1008 : Float(232, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1010 : Float(232, 232, 1, 1, strides=[232, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %1011 : Float(232, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1013 : Float(232, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %1014 : Float(232, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1016 : Float(232, 232, 1, 1, strides=[232, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %1017 : Float(232, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1019 : Float(1024, 464, 1, 1, strides=[464, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %1020 : Float(1024, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1026 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1031 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1037 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1042 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1048 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1053 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1059 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1064 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1070 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1075 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1081 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1086 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1092 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1097 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1103 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1108 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1114 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1119 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1125 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1130 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1136 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1141 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1147 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1152 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1158 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1163 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1169 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1174 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1180 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1185 : Long(4, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1191 : Long(5, strides=[1], requires_grad=0, device=cpu),\n",
      "      %1196 : Long(4, strides=[1], requires_grad=0, device=cpu)):\n",
      "  %853 : Float(1, 24, 112, 112, strides=[301056, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%input.1, %854, %855)\n",
      "  %341 : Float(1, 24, 112, 112, strides=[301056, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::Relu(%853) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %342 : Float(1, 24, 56, 56, strides=[75264, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%341) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:719:0\n",
      "  %856 : Float(1, 24, 28, 28, strides=[18816, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=24, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%342, %857, %858)\n",
      "  %859 : Float(1, 58, 28, 28, strides=[45472, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%856, %860, %861)\n",
      "  %347 : Float(1, 58, 28, 28, strides=[45472, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Relu(%859) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %862 : Float(1, 58, 56, 56, strides=[181888, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%342, %863, %864)\n",
      "  %350 : Float(1, 58, 56, 56, strides=[181888, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Relu(%862) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %865 : Float(1, 58, 28, 28, strides=[45472, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=58, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%350, %866, %867)\n",
      "  %868 : Float(1, 58, 28, 28, strides=[45472, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%865, %869, %870)\n",
      "  %355 : Float(1, 58, 28, 28, strides=[45472, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Relu(%868) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %356 : Float(1, 116, 28, 28, strides=[90944, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%347, %355) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:92:0\n",
      "  %368 : Float(1, 2, 58, 28, 28, strides=[90944, 45472, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Reshape(%356, %1026) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:27:0\n",
      "  %369 : Float(1, 58, 2, 28, 28, strides=[90944, 1568, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3, 4]](%368) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:29:0\n",
      "  %376 : Float(1, 116, 28, 28, strides=[90944, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Reshape(%369, %1031) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:32:0\n",
      "  %377 : Float(1, 58, 28, 28, strides=[90944, 784, 28, 1], requires_grad=1, device=cpu), %378 : Float(1, 58, 28, 28, strides=[90944, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, split=[58, 58]](%376)\n",
      "  %871 : Float(1, 58, 28, 28, strides=[45472, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%378, %872, %873)\n",
      "  %381 : Float(1, 58, 28, 28, strides=[45472, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Relu(%871) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %874 : Float(1, 58, 28, 28, strides=[45472, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=58, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%381, %875, %876)\n",
      "  %877 : Float(1, 58, 28, 28, strides=[45472, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%874, %878, %879)\n",
      "  %386 : Float(1, 58, 28, 28, strides=[45472, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Relu(%877) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %387 : Float(1, 116, 28, 28, strides=[90944, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%377, %386) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:90:0\n",
      "  %399 : Float(1, 2, 58, 28, 28, strides=[90944, 45472, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Reshape(%387, %1037) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:27:0\n",
      "  %400 : Float(1, 58, 2, 28, 28, strides=[90944, 1568, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3, 4]](%399) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:29:0\n",
      "  %407 : Float(1, 116, 28, 28, strides=[90944, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Reshape(%400, %1042) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:32:0\n",
      "  %408 : Float(1, 58, 28, 28, strides=[90944, 784, 28, 1], requires_grad=1, device=cpu), %409 : Float(1, 58, 28, 28, strides=[90944, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, split=[58, 58]](%407)\n",
      "  %880 : Float(1, 58, 28, 28, strides=[45472, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%409, %881, %882)\n",
      "  %412 : Float(1, 58, 28, 28, strides=[45472, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Relu(%880) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %883 : Float(1, 58, 28, 28, strides=[45472, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=58, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%412, %884, %885)\n",
      "  %886 : Float(1, 58, 28, 28, strides=[45472, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%883, %887, %888)\n",
      "  %417 : Float(1, 58, 28, 28, strides=[45472, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Relu(%886) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %418 : Float(1, 116, 28, 28, strides=[90944, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%408, %417) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:90:0\n",
      "  %430 : Float(1, 2, 58, 28, 28, strides=[90944, 45472, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Reshape(%418, %1048) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:27:0\n",
      "  %431 : Float(1, 58, 2, 28, 28, strides=[90944, 1568, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3, 4]](%430) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:29:0\n",
      "  %438 : Float(1, 116, 28, 28, strides=[90944, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Reshape(%431, %1053) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:32:0\n",
      "  %439 : Float(1, 58, 28, 28, strides=[90944, 784, 28, 1], requires_grad=1, device=cpu), %440 : Float(1, 58, 28, 28, strides=[90944, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, split=[58, 58]](%438)\n",
      "  %889 : Float(1, 58, 28, 28, strides=[45472, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%440, %890, %891)\n",
      "  %443 : Float(1, 58, 28, 28, strides=[45472, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Relu(%889) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %892 : Float(1, 58, 28, 28, strides=[45472, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=58, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%443, %893, %894)\n",
      "  %895 : Float(1, 58, 28, 28, strides=[45472, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%892, %896, %897)\n",
      "  %448 : Float(1, 58, 28, 28, strides=[45472, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Relu(%895) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %449 : Float(1, 116, 28, 28, strides=[90944, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%439, %448) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:90:0\n",
      "  %461 : Float(1, 2, 58, 28, 28, strides=[90944, 45472, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Reshape(%449, %1059) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:27:0\n",
      "  %462 : Float(1, 58, 2, 28, 28, strides=[90944, 1568, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3, 4]](%461) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:29:0\n",
      "  %469 : Float(1, 116, 28, 28, strides=[90944, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Reshape(%462, %1064) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:32:0\n",
      "  %898 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=116, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%469, %899, %900)\n",
      "  %901 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%898, %902, %903)\n",
      "  %474 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Relu(%901) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %904 : Float(1, 116, 28, 28, strides=[90944, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%469, %905, %906)\n",
      "  %477 : Float(1, 116, 28, 28, strides=[90944, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Relu(%904) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %907 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=116, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%477, %908, %909)\n",
      "  %910 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%907, %911, %912)\n",
      "  %482 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Relu(%910) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %483 : Float(1, 232, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%474, %482) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:92:0\n",
      "  %495 : Float(1, 2, 116, 14, 14, strides=[45472, 22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Reshape(%483, %1070) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:27:0\n",
      "  %496 : Float(1, 116, 2, 14, 14, strides=[45472, 392, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3, 4]](%495) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:29:0\n",
      "  %503 : Float(1, 232, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Reshape(%496, %1075) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:32:0\n",
      "  %504 : Float(1, 116, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu), %505 : Float(1, 116, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, split=[116, 116]](%503)\n",
      "  %913 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%505, %914, %915)\n",
      "  %508 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Relu(%913) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %916 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=116, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%508, %917, %918)\n",
      "  %919 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%916, %920, %921)\n",
      "  %513 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Relu(%919) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %514 : Float(1, 232, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%504, %513) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:90:0\n",
      "  %526 : Float(1, 2, 116, 14, 14, strides=[45472, 22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Reshape(%514, %1081) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:27:0\n",
      "  %527 : Float(1, 116, 2, 14, 14, strides=[45472, 392, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3, 4]](%526) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:29:0\n",
      "  %534 : Float(1, 232, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Reshape(%527, %1086) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:32:0\n",
      "  %535 : Float(1, 116, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu), %536 : Float(1, 116, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, split=[116, 116]](%534)\n",
      "  %922 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%536, %923, %924)\n",
      "  %539 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Relu(%922) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %925 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=116, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%539, %926, %927)\n",
      "  %928 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%925, %929, %930)\n",
      "  %544 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Relu(%928) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %545 : Float(1, 232, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%535, %544) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:90:0\n",
      "  %557 : Float(1, 2, 116, 14, 14, strides=[45472, 22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Reshape(%545, %1092) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:27:0\n",
      "  %558 : Float(1, 116, 2, 14, 14, strides=[45472, 392, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3, 4]](%557) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:29:0\n",
      "  %565 : Float(1, 232, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Reshape(%558, %1097) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:32:0\n",
      "  %566 : Float(1, 116, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu), %567 : Float(1, 116, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, split=[116, 116]](%565)\n",
      "  %931 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%567, %932, %933)\n",
      "  %570 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Relu(%931) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %934 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=116, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%570, %935, %936)\n",
      "  %937 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%934, %938, %939)\n",
      "  %575 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Relu(%937) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %576 : Float(1, 232, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%566, %575) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:90:0\n",
      "  %588 : Float(1, 2, 116, 14, 14, strides=[45472, 22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Reshape(%576, %1103) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:27:0\n",
      "  %589 : Float(1, 116, 2, 14, 14, strides=[45472, 392, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3, 4]](%588) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:29:0\n",
      "  %596 : Float(1, 232, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Reshape(%589, %1108) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:32:0\n",
      "  %597 : Float(1, 116, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu), %598 : Float(1, 116, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, split=[116, 116]](%596)\n",
      "  %940 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%598, %941, %942)\n",
      "  %601 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Relu(%940) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %943 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=116, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%601, %944, %945)\n",
      "  %946 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%943, %947, %948)\n",
      "  %606 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Relu(%946) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %607 : Float(1, 232, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%597, %606) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:90:0\n",
      "  %619 : Float(1, 2, 116, 14, 14, strides=[45472, 22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Reshape(%607, %1114) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:27:0\n",
      "  %620 : Float(1, 116, 2, 14, 14, strides=[45472, 392, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3, 4]](%619) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:29:0\n",
      "  %627 : Float(1, 232, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Reshape(%620, %1119) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:32:0\n",
      "  %628 : Float(1, 116, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu), %629 : Float(1, 116, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, split=[116, 116]](%627)\n",
      "  %949 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%629, %950, %951)\n",
      "  %632 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Relu(%949) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %952 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=116, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%632, %953, %954)\n",
      "  %955 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%952, %956, %957)\n",
      "  %637 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Relu(%955) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %638 : Float(1, 232, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%628, %637) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:90:0\n",
      "  %650 : Float(1, 2, 116, 14, 14, strides=[45472, 22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Reshape(%638, %1125) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:27:0\n",
      "  %651 : Float(1, 116, 2, 14, 14, strides=[45472, 392, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3, 4]](%650) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:29:0\n",
      "  %658 : Float(1, 232, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Reshape(%651, %1130) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:32:0\n",
      "  %659 : Float(1, 116, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu), %660 : Float(1, 116, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, split=[116, 116]](%658)\n",
      "  %958 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%660, %959, %960)\n",
      "  %663 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Relu(%958) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %961 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=116, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%663, %962, %963)\n",
      "  %964 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%961, %965, %966)\n",
      "  %668 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Relu(%964) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %669 : Float(1, 232, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%659, %668) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:90:0\n",
      "  %681 : Float(1, 2, 116, 14, 14, strides=[45472, 22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Reshape(%669, %1136) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:27:0\n",
      "  %682 : Float(1, 116, 2, 14, 14, strides=[45472, 392, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3, 4]](%681) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:29:0\n",
      "  %689 : Float(1, 232, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Reshape(%682, %1141) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:32:0\n",
      "  %690 : Float(1, 116, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu), %691 : Float(1, 116, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, split=[116, 116]](%689)\n",
      "  %967 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%691, %968, %969)\n",
      "  %694 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Relu(%967) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %970 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=116, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%694, %971, %972)\n",
      "  %973 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%970, %974, %975)\n",
      "  %699 : Float(1, 116, 14, 14, strides=[22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Relu(%973) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %700 : Float(1, 232, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%690, %699) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:90:0\n",
      "  %712 : Float(1, 2, 116, 14, 14, strides=[45472, 22736, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Reshape(%700, %1147) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:27:0\n",
      "  %713 : Float(1, 116, 2, 14, 14, strides=[45472, 392, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3, 4]](%712) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:29:0\n",
      "  %720 : Float(1, 232, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Reshape(%713, %1152) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:32:0\n",
      "  %976 : Float(1, 232, 7, 7, strides=[11368, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=232, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%720, %977, %978)\n",
      "  %979 : Float(1, 232, 7, 7, strides=[11368, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%976, %980, %981)\n",
      "  %725 : Float(1, 232, 7, 7, strides=[11368, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Relu(%979) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %982 : Float(1, 232, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%720, %983, %984)\n",
      "  %728 : Float(1, 232, 14, 14, strides=[45472, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Relu(%982) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %985 : Float(1, 232, 7, 7, strides=[11368, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=232, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%728, %986, %987)\n",
      "  %988 : Float(1, 232, 7, 7, strides=[11368, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%985, %989, %990)\n",
      "  %733 : Float(1, 232, 7, 7, strides=[11368, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Relu(%988) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %734 : Float(1, 464, 7, 7, strides=[22736, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%725, %733) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:92:0\n",
      "  %746 : Float(1, 2, 232, 7, 7, strides=[22736, 11368, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Reshape(%734, %1158) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:27:0\n",
      "  %747 : Float(1, 232, 2, 7, 7, strides=[22736, 98, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3, 4]](%746) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:29:0\n",
      "  %754 : Float(1, 464, 7, 7, strides=[22736, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Reshape(%747, %1163) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:32:0\n",
      "  %755 : Float(1, 232, 7, 7, strides=[22736, 49, 7, 1], requires_grad=1, device=cpu), %756 : Float(1, 232, 7, 7, strides=[22736, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, split=[232, 232]](%754)\n",
      "  %991 : Float(1, 232, 7, 7, strides=[11368, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%756, %992, %993)\n",
      "  %759 : Float(1, 232, 7, 7, strides=[11368, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Relu(%991) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %994 : Float(1, 232, 7, 7, strides=[11368, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=232, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%759, %995, %996)\n",
      "  %997 : Float(1, 232, 7, 7, strides=[11368, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%994, %998, %999)\n",
      "  %764 : Float(1, 232, 7, 7, strides=[11368, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Relu(%997) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %765 : Float(1, 464, 7, 7, strides=[22736, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%755, %764) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:90:0\n",
      "  %777 : Float(1, 2, 232, 7, 7, strides=[22736, 11368, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Reshape(%765, %1169) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:27:0\n",
      "  %778 : Float(1, 232, 2, 7, 7, strides=[22736, 98, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3, 4]](%777) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:29:0\n",
      "  %785 : Float(1, 464, 7, 7, strides=[22736, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Reshape(%778, %1174) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:32:0\n",
      "  %786 : Float(1, 232, 7, 7, strides=[22736, 49, 7, 1], requires_grad=1, device=cpu), %787 : Float(1, 232, 7, 7, strides=[22736, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, split=[232, 232]](%785)\n",
      "  %1000 : Float(1, 232, 7, 7, strides=[11368, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%787, %1001, %1002)\n",
      "  %790 : Float(1, 232, 7, 7, strides=[11368, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Relu(%1000) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %1003 : Float(1, 232, 7, 7, strides=[11368, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=232, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%790, %1004, %1005)\n",
      "  %1006 : Float(1, 232, 7, 7, strides=[11368, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1003, %1007, %1008)\n",
      "  %795 : Float(1, 232, 7, 7, strides=[11368, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Relu(%1006) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %796 : Float(1, 464, 7, 7, strides=[22736, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%786, %795) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:90:0\n",
      "  %808 : Float(1, 2, 232, 7, 7, strides=[22736, 11368, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Reshape(%796, %1180) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:27:0\n",
      "  %809 : Float(1, 232, 2, 7, 7, strides=[22736, 98, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3, 4]](%808) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:29:0\n",
      "  %816 : Float(1, 464, 7, 7, strides=[22736, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Reshape(%809, %1185) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:32:0\n",
      "  %817 : Float(1, 232, 7, 7, strides=[22736, 49, 7, 1], requires_grad=1, device=cpu), %818 : Float(1, 232, 7, 7, strides=[22736, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1, split=[232, 232]](%816)\n",
      "  %1009 : Float(1, 232, 7, 7, strides=[11368, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%818, %1010, %1011)\n",
      "  %821 : Float(1, 232, 7, 7, strides=[11368, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Relu(%1009) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %1012 : Float(1, 232, 7, 7, strides=[11368, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=232, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%821, %1013, %1014)\n",
      "  %1015 : Float(1, 232, 7, 7, strides=[11368, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1012, %1016, %1017)\n",
      "  %826 : Float(1, 232, 7, 7, strides=[11368, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Relu(%1015) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %827 : Float(1, 464, 7, 7, strides=[22736, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%817, %826) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:90:0\n",
      "  %839 : Float(1, 2, 232, 7, 7, strides=[22736, 11368, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Reshape(%827, %1191) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:27:0\n",
      "  %840 : Float(1, 232, 2, 7, 7, strides=[22736, 98, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3, 4]](%839) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:29:0\n",
      "  %847 : Float(1, 464, 7, 7, strides=[22736, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Reshape(%840, %1196) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:32:0\n",
      "  %1018 : Float(1, 1024, 7, 7, strides=[50176, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%847, %1019, %1020)\n",
      "  %850 : Float(1, 1024, 7, 7, strides=[50176, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Relu(%1018) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %851 : Float(1, 1024, strides=[1024, 1], requires_grad=1, device=cpu) = onnx::ReduceMean[axes=[2, 3], keepdims=0](%850) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/shufflenetv2.py:156:0\n",
      "  %852 : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%851, %fc.weight, %fc.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1848:0\n",
      "  return (%852)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.onnx\n",
    "\n",
    "# Load the pre-trained ShuffleNet model\n",
    "model = models.shufflenet_v2_x1_0(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Specify the input size\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Convert the PyTorch model to ONNX\n",
    "onnx_path = 'shufflenet.onnx'\n",
    "torch.onnx.export(model, dummy_input, onnx_path, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7930b0c-34d7-43cd-9e41-0bb47fd2886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f44c10c2-80fa-4228-86ee-98be9d9a11dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&& RUNNING TensorRT.trtexec [TensorRT v8201] # /usr/src/tensorrt/bin/trtexec --onnx=/nvdli-nano/data/Inference/MODELS/Model_6/shufflenet.onnx --saveEngine=/nvdli-nano/data/Inference/MODELS/Model_6/shufflenet.trt\n",
      "[02/08/2024-05:54:45] [I] === Model Options ===\n",
      "[02/08/2024-05:54:45] [I] Format: ONNX\n",
      "[02/08/2024-05:54:45] [I] Model: /nvdli-nano/data/Inference/MODELS/Model_6/shufflenet.onnx\n",
      "[02/08/2024-05:54:45] [I] Output:\n",
      "[02/08/2024-05:54:45] [I] === Build Options ===\n",
      "[02/08/2024-05:54:45] [I] Max batch: explicit batch\n",
      "[02/08/2024-05:54:45] [I] Workspace: 16 MiB\n",
      "[02/08/2024-05:54:45] [I] minTiming: 1\n",
      "[02/08/2024-05:54:45] [I] avgTiming: 8\n",
      "[02/08/2024-05:54:45] [I] Precision: FP32\n",
      "[02/08/2024-05:54:45] [I] Calibration: \n",
      "[02/08/2024-05:54:45] [I] Refit: Disabled\n",
      "[02/08/2024-05:54:45] [I] Sparsity: Disabled\n",
      "[02/08/2024-05:54:45] [I] Safe mode: Disabled\n",
      "[02/08/2024-05:54:45] [I] DirectIO mode: Disabled\n",
      "[02/08/2024-05:54:45] [I] Restricted mode: Disabled\n",
      "[02/08/2024-05:54:45] [I] Save engine: /nvdli-nano/data/Inference/MODELS/Model_6/shufflenet.trt\n",
      "[02/08/2024-05:54:45] [I] Load engine: \n",
      "[02/08/2024-05:54:45] [I] Profiling verbosity: 0\n",
      "[02/08/2024-05:54:45] [I] Tactic sources: Using default tactic sources\n",
      "[02/08/2024-05:54:45] [I] timingCacheMode: local\n",
      "[02/08/2024-05:54:45] [I] timingCacheFile: \n",
      "[02/08/2024-05:54:45] [I] Input(s)s format: fp32:CHW\n",
      "[02/08/2024-05:54:45] [I] Output(s)s format: fp32:CHW\n",
      "[02/08/2024-05:54:45] [I] Input build shapes: model\n",
      "[02/08/2024-05:54:45] [I] Input calibration shapes: model\n",
      "[02/08/2024-05:54:45] [I] === System Options ===\n",
      "[02/08/2024-05:54:45] [I] Device: 0\n",
      "[02/08/2024-05:54:45] [I] DLACore: \n",
      "[02/08/2024-05:54:45] [I] Plugins:\n",
      "[02/08/2024-05:54:45] [I] === Inference Options ===\n",
      "[02/08/2024-05:54:45] [I] Batch: Explicit\n",
      "[02/08/2024-05:54:45] [I] Input inference shapes: model\n",
      "[02/08/2024-05:54:45] [I] Iterations: 10\n",
      "[02/08/2024-05:54:45] [I] Duration: 3s (+ 200ms warm up)\n",
      "[02/08/2024-05:54:45] [I] Sleep time: 0ms\n",
      "[02/08/2024-05:54:45] [I] Idle time: 0ms\n",
      "[02/08/2024-05:54:45] [I] Streams: 1\n",
      "[02/08/2024-05:54:45] [I] ExposeDMA: Disabled\n",
      "[02/08/2024-05:54:45] [I] Data transfers: Enabled\n",
      "[02/08/2024-05:54:45] [I] Spin-wait: Disabled\n",
      "[02/08/2024-05:54:45] [I] Multithreading: Disabled\n",
      "[02/08/2024-05:54:45] [I] CUDA Graph: Disabled\n",
      "[02/08/2024-05:54:45] [I] Separate profiling: Disabled\n",
      "[02/08/2024-05:54:45] [I] Time Deserialize: Disabled\n",
      "[02/08/2024-05:54:45] [I] Time Refit: Disabled\n",
      "[02/08/2024-05:54:45] [I] Skip inference: Disabled\n",
      "[02/08/2024-05:54:45] [I] Inputs:\n",
      "[02/08/2024-05:54:45] [I] === Reporting Options ===\n",
      "[02/08/2024-05:54:45] [I] Verbose: Disabled\n",
      "[02/08/2024-05:54:45] [I] Averages: 10 inferences\n",
      "[02/08/2024-05:54:45] [I] Percentile: 99\n",
      "[02/08/2024-05:54:45] [I] Dump refittable layers:Disabled\n",
      "[02/08/2024-05:54:45] [I] Dump output: Disabled\n",
      "[02/08/2024-05:54:45] [I] Profile: Disabled\n",
      "[02/08/2024-05:54:45] [I] Export timing to JSON file: \n",
      "[02/08/2024-05:54:45] [I] Export output to JSON file: \n",
      "[02/08/2024-05:54:45] [I] Export profile to JSON file: \n",
      "[02/08/2024-05:54:45] [I] \n",
      "[02/08/2024-05:54:46] [I] === Device Information ===\n",
      "[02/08/2024-05:54:46] [I] Selected Device: NVIDIA Tegra X1\n",
      "[02/08/2024-05:54:46] [I] Compute Capability: 5.3\n",
      "[02/08/2024-05:54:46] [I] SMs: 1\n",
      "[02/08/2024-05:54:46] [I] Compute Clock Rate: 0.9216 GHz\n",
      "[02/08/2024-05:54:46] [I] Device Global Memory: 3956 MiB\n",
      "[02/08/2024-05:54:46] [I] Shared Memory per SM: 64 KiB\n",
      "[02/08/2024-05:54:46] [I] Memory Bus Width: 64 bits (ECC disabled)\n",
      "[02/08/2024-05:54:46] [I] Memory Clock Rate: 0.01275 GHz\n",
      "[02/08/2024-05:54:46] [I] \n",
      "[02/08/2024-05:54:46] [I] TensorRT version: 8.2.1\n",
      "[02/08/2024-05:55:08] [I] [TRT] [MemUsageChange] Init CUDA: CPU +229, GPU -8, now: CPU 248, GPU 3896 (MiB)\n",
      "[02/08/2024-05:55:19] [I] [TRT] [MemUsageSnapshot] Begin constructing builder kernel library: CPU 248 MiB, GPU 3857 MiB\n",
      "[02/08/2024-05:55:20] [I] [TRT] [MemUsageSnapshot] End constructing builder kernel library: CPU 278 MiB, GPU 3886 MiB\n",
      "[02/08/2024-05:55:20] [I] Start parsing network model\n",
      "[02/08/2024-05:55:21] [I] [TRT] ----------------------------------------------------------------\n",
      "[02/08/2024-05:55:22] [I] [TRT] Input filename:   /nvdli-nano/data/Inference/MODELS/Model_6/shufflenet.onnx\n",
      "[02/08/2024-05:55:22] [I] [TRT] ONNX IR version:  0.0.7\n",
      "[02/08/2024-05:55:22] [I] [TRT] Opset version:    9\n",
      "[02/08/2024-05:55:22] [I] [TRT] Producer name:    pytorch\n",
      "[02/08/2024-05:55:22] [I] [TRT] Producer version: 1.10\n",
      "[02/08/2024-05:55:22] [I] [TRT] Domain:           \n",
      "[02/08/2024-05:55:22] [I] [TRT] Model version:    0\n",
      "[02/08/2024-05:55:22] [I] [TRT] Doc string:       \n",
      "[02/08/2024-05:55:22] [I] [TRT] ----------------------------------------------------------------\n",
      "[02/08/2024-05:55:22] [W] [TRT] onnx2trt_utils.cpp:366: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "[02/08/2024-05:55:22] [I] Finish parsing network model\n",
      "[02/08/2024-05:55:23] [I] [TRT] ---------- Layers Running on DLA ----------\n",
      "[02/08/2024-05:55:23] [I] [TRT] ---------- Layers Running on GPU ----------\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_0 + Relu_1\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] MaxPool_2\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_3\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_4 + Relu_5\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_6 + Relu_7\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_8\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_9 + Relu_10\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_12 + Transpose_13\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_14\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Split_15\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Split_15_0\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_16 + Relu_17\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_18\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_19 + Relu_20\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_22 + Transpose_23\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_24\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Split_25\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Split_25_1\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_26 + Relu_27\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_28\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_29 + Relu_30\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_32 + Transpose_33\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_34\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Split_35\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Split_35_2\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_36 + Relu_37\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_38\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_39 + Relu_40\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_42 + Transpose_43\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_44\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_45\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_46 + Relu_47\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_48 + Relu_49\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_50\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_51 + Relu_52\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_54 + Transpose_55\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_56\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Split_57\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Split_57_3\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_58 + Relu_59\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_60\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_61 + Relu_62\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_64 + Transpose_65\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_66\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Split_67\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Split_67_4\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_68 + Relu_69\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_70\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_71 + Relu_72\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_74 + Transpose_75\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_76\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Split_77\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Split_77_5\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_78 + Relu_79\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_80\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_81 + Relu_82\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_84 + Transpose_85\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_86\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Split_87\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Split_87_6\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_88 + Relu_89\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_90\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_91 + Relu_92\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_94 + Transpose_95\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_96\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Split_97\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Split_97_7\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_98 + Relu_99\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_100\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_101 + Relu_102\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_104 + Transpose_105\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_106\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Split_107\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Split_107_8\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_108 + Relu_109\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_110\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_111 + Relu_112\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_114 + Transpose_115\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_116\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Split_117\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Split_117_9\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_118 + Relu_119\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_120\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_121 + Relu_122\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_124 + Transpose_125\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_126\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_127\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_128 + Relu_129\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_130 + Relu_131\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_132\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_133 + Relu_134\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_136 + Transpose_137\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_138\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Split_139\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Split_139_10\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_140 + Relu_141\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_142\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_143 + Relu_144\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_146 + Transpose_147\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_148\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Split_149\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Split_149_11\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_150 + Relu_151\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_152\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_153 + Relu_154\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_156 + Transpose_157\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_158\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Split_159\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Split_159_12\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_160 + Relu_161\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_162\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_163 + Relu_164\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_166 + Transpose_167\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Reshape_168\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Conv_169 + Relu_170\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] ReduceMean_171\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] (Unnamed Layer* 185) [Shuffle]\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] Gemm_172\n",
      "[02/08/2024-05:55:23] [I] [TRT] [GpuLayer] (Unnamed Layer* 187) [Shuffle]\n",
      "[02/08/2024-05:56:07] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +158, GPU -38, now: CPU 446, GPU 3866 (MiB)\n",
      "[02/08/2024-05:56:54] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +241, GPU +37, now: CPU 687, GPU 3904 (MiB)\n",
      "[02/08/2024-05:56:56] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[02/08/2024-05:58:03] [I] [TRT] Some tactics do not have sufficient workspace memory to run. Increasing workspace size may increase performance, please check verbose output.\n",
      "[02/08/2024-05:58:53] [I] [TRT] Detected 1 inputs and 1 output network tensors.\n",
      "[02/08/2024-05:58:53] [I] [TRT] Total Host Persistent Memory: 155680\n",
      "[02/08/2024-05:58:53] [I] [TRT] Total Device Persistent Memory: 3368960\n",
      "[02/08/2024-05:58:53] [I] [TRT] Total Scratch Memory: 114688\n",
      "[02/08/2024-05:58:53] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 3 MiB, GPU 24 MiB\n",
      "[02/08/2024-05:58:53] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 28.1094ms to assign 4 blocks to 104 nodes requiring 1869313 bytes.\n",
      "[02/08/2024-05:58:53] [I] [TRT] Total Activation Memory: 1869313\n",
      "[02/08/2024-05:58:53] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +3, now: CPU 934, GPU 3865 (MiB)\n",
      "[02/08/2024-05:58:53] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU -3, now: CPU 935, GPU 3862 (MiB)\n",
      "[02/08/2024-05:58:53] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +16, now: CPU 0, GPU 16 (MiB)\n",
      "[02/08/2024-05:58:53] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 939, GPU 3867 (MiB)\n",
      "[02/08/2024-05:58:53] [I] [TRT] Loaded engine size: 9 MiB\n",
      "[02/08/2024-05:58:53] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +1, now: CPU 939, GPU 3857 (MiB)\n",
      "[02/08/2024-05:58:53] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +1, now: CPU 939, GPU 3858 (MiB)\n",
      "[02/08/2024-05:58:53] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +8, now: CPU 0, GPU 8 (MiB)\n",
      "[02/08/2024-05:58:53] [I] Engine built in 247.641 sec.\n",
      "[02/08/2024-05:58:54] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +1, GPU +1, now: CPU 900, GPU 3855 (MiB)\n",
      "[02/08/2024-05:58:54] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +2, now: CPU 900, GPU 3857 (MiB)\n",
      "[02/08/2024-05:58:54] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +5, now: CPU 0, GPU 13 (MiB)\n",
      "[02/08/2024-05:58:54] [I] Using random values for input input.1\n",
      "[02/08/2024-05:58:54] [I] Created input binding for input.1 with dimensions 1x3x224x224\n",
      "[02/08/2024-05:58:54] [I] Using random values for output 852\n",
      "[02/08/2024-05:58:54] [I] Created output binding for 852 with dimensions 1x1000\n",
      "[02/08/2024-05:58:54] [I] Starting inference\n",
      "[02/08/2024-05:58:57] [I] Warmup completed 1 queries over 200 ms\n",
      "[02/08/2024-05:58:57] [I] Timing trace has 212 queries over 2.53268 s\n",
      "[02/08/2024-05:58:57] [I] \n",
      "[02/08/2024-05:58:57] [I] === Trace details ===\n",
      "[02/08/2024-05:58:57] [I] Trace averages of 10 runs:\n",
      "[02/08/2024-05:58:57] [I] Average on 10 runs - GPU latency: 11.8538 ms - Host latency: 11.9287 ms (end to end 11.9518 ms, enqueue 10.8162 ms)\n",
      "[02/08/2024-05:58:57] [I] Average on 10 runs - GPU latency: 11.2697 ms - Host latency: 11.3311 ms (end to end 11.3448 ms, enqueue 10.8948 ms)\n",
      "[02/08/2024-05:58:57] [I] Average on 10 runs - GPU latency: 11.1487 ms - Host latency: 11.2108 ms (end to end 11.2247 ms, enqueue 10.8277 ms)\n",
      "[02/08/2024-05:58:57] [I] Average on 10 runs - GPU latency: 11.576 ms - Host latency: 11.6379 ms (end to end 11.6516 ms, enqueue 11.392 ms)\n",
      "[02/08/2024-05:58:57] [I] Average on 10 runs - GPU latency: 13.5129 ms - Host latency: 13.5759 ms (end to end 13.5896 ms, enqueue 13.4503 ms)\n",
      "[02/08/2024-05:58:57] [I] Average on 10 runs - GPU latency: 11.765 ms - Host latency: 11.8264 ms (end to end 11.84 ms, enqueue 11.3018 ms)\n",
      "[02/08/2024-05:58:57] [I] Average on 10 runs - GPU latency: 11.9147 ms - Host latency: 11.9766 ms (end to end 11.9892 ms, enqueue 9.92178 ms)\n",
      "[02/08/2024-05:58:57] [I] Average on 10 runs - GPU latency: 11.9978 ms - Host latency: 12.0582 ms (end to end 12.0686 ms, enqueue 8.39679 ms)\n",
      "[02/08/2024-05:58:57] [I] Average on 10 runs - GPU latency: 14.5267 ms - Host latency: 14.5921 ms (end to end 14.604 ms, enqueue 10.0654 ms)\n",
      "[02/08/2024-05:58:57] [I] Average on 10 runs - GPU latency: 12.7796 ms - Host latency: 12.8477 ms (end to end 12.8584 ms, enqueue 9.42424 ms)\n",
      "[02/08/2024-05:58:57] [I] Average on 10 runs - GPU latency: 12.5637 ms - Host latency: 12.6245 ms (end to end 12.6446 ms, enqueue 8.29971 ms)\n",
      "[02/08/2024-05:58:57] [I] Average on 10 runs - GPU latency: 13.7285 ms - Host latency: 13.7907 ms (end to end 13.9362 ms, enqueue 9.02642 ms)\n",
      "[02/08/2024-05:58:57] [I] Average on 10 runs - GPU latency: 11.4855 ms - Host latency: 11.547 ms (end to end 11.5568 ms, enqueue 7.41868 ms)\n",
      "[02/08/2024-05:58:57] [I] Average on 10 runs - GPU latency: 12.542 ms - Host latency: 12.6128 ms (end to end 12.6227 ms, enqueue 8.97942 ms)\n",
      "[02/08/2024-05:58:57] [I] Average on 10 runs - GPU latency: 11.0451 ms - Host latency: 11.1051 ms (end to end 11.1152 ms, enqueue 6.95078 ms)\n",
      "[02/08/2024-05:58:57] [I] Average on 10 runs - GPU latency: 11.582 ms - Host latency: 11.6425 ms (end to end 11.6522 ms, enqueue 7.08533 ms)\n",
      "[02/08/2024-05:58:57] [I] Average on 10 runs - GPU latency: 12.4198 ms - Host latency: 12.4917 ms (end to end 12.5524 ms, enqueue 10.0137 ms)\n",
      "[02/08/2024-05:58:57] [I] Average on 10 runs - GPU latency: 10.4341 ms - Host latency: 10.4942 ms (end to end 10.5044 ms, enqueue 6.40742 ms)\n",
      "[02/08/2024-05:58:57] [I] Average on 10 runs - GPU latency: 10.0218 ms - Host latency: 10.0816 ms (end to end 10.092 ms, enqueue 6.06997 ms)\n",
      "[02/08/2024-05:58:57] [I] Average on 10 runs - GPU latency: 10.0536 ms - Host latency: 10.1132 ms (end to end 10.1233 ms, enqueue 6.13872 ms)\n",
      "[02/08/2024-05:58:57] [I] Average on 10 runs - GPU latency: 11.0287 ms - Host latency: 11.0891 ms (end to end 11.0992 ms, enqueue 7.11145 ms)\n",
      "[02/08/2024-05:58:57] [I] \n",
      "[02/08/2024-05:58:57] [I] === Performance summary ===\n",
      "[02/08/2024-05:58:57] [I] Throughput: 83.7056 qps\n",
      "[02/08/2024-05:58:57] [I] Latency: min = 9.8186 ms, max = 20.0607 ms, mean = 11.925 ms, median = 11.3929 ms, percentile(99%) = 18.9319 ms\n",
      "[02/08/2024-05:58:57] [I] End-to-End Host Latency: min = 9.8291 ms, max = 20.0708 ms, mean = 11.946 ms, median = 11.4063 ms, percentile(99%) = 18.9421 ms\n",
      "[02/08/2024-05:58:57] [I] Enqueue Time: min = 5.57544 ms, max = 16.6545 ms, mean = 9.02868 ms, median = 8.927 ms, percentile(99%) = 15.1991 ms\n",
      "[02/08/2024-05:58:57] [I] H2D Latency: min = 0.0554199 ms, max = 0.197693 ms, mean = 0.0604182 ms, median = 0.058136 ms, percentile(99%) = 0.154541 ms\n",
      "[02/08/2024-05:58:57] [I] GPU Compute Time: min = 9.7561 ms, max = 19.9985 ms, mean = 11.8618 ms, median = 11.3309 ms, percentile(99%) = 18.8696 ms\n",
      "[02/08/2024-05:58:57] [I] D2H Latency: min = 0.00146484 ms, max = 0.00366211 ms, mean = 0.00279034 ms, median = 0.00292969 ms, percentile(99%) = 0.00341797 ms\n",
      "[02/08/2024-05:58:57] [I] Total Host Walltime: 2.53268 s\n",
      "[02/08/2024-05:58:57] [I] Total GPU Compute Time: 2.5147 s\n",
      "[02/08/2024-05:58:57] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
      "[02/08/2024-05:58:57] [I] \n",
      "&&&& PASSED TensorRT.trtexec [TensorRT v8201] # /usr/src/tensorrt/bin/trtexec --onnx=/nvdli-nano/data/Inference/MODELS/Model_6/shufflenet.onnx --saveEngine=/nvdli-nano/data/Inference/MODELS/Model_6/shufflenet.trt\n"
     ]
    }
   ],
   "source": [
    "!/usr/src/tensorrt/bin/trtexec --onnx=/nvdli-nano/data/Inference/MODELS/Model_6/shufflenet.onnx --saveEngine=/nvdli-nano/data/Inference/MODELS/Model_6/shufflenet.trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b54e5fac-9125-4c7e-85b9-312858d96bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: cats\n",
      "Inference time: 0.3463137149810791 seconds\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorrt as trt\n",
    "import time\n",
    "\n",
    "# Load the TensorRT model\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "with open('shufflenet.trt', 'rb') as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "    engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "# Load and preprocess the input image\n",
    "image_path = '1.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.resize(image, (224, 224))\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "image = image.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
    "image = np.transpose(image, (2, 0, 1))  # Change to channel-first format\n",
    "\n",
    "# Convert to torch tensor\n",
    "image_tensor = torch.tensor(image, dtype=torch.float32)\n",
    "\n",
    "# Run inference and measure time\n",
    "with torch.no_grad():\n",
    "    # Convert the tensor to a batched format\n",
    "    input_data = image_tensor.unsqueeze(0)\n",
    "\n",
    "    # Transfer the input tensor to GPU (if available)\n",
    "    if torch.cuda.is_available():\n",
    "        input_data = input_data.to('cuda')\n",
    "\n",
    "    # Allocate device memory for the input tensor\n",
    "    d_input = torch.cuda.FloatTensor(input_data)\n",
    "\n",
    "    # Allocate device memory for the output tensor\n",
    "    d_output = torch.empty((1, 2), device='cuda')  # Assuming 2 classes (dogs and cats)\n",
    "\n",
    "    # Measure inference time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Run inference\n",
    "    context.execute(1, bindings=[int(d_input.data_ptr()), int(d_output.data_ptr())])\n",
    "\n",
    "    # Measure elapsed time\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    # Transfer the output tensor back to the host\n",
    "    h_output = d_output.cpu().numpy()\n",
    "\n",
    "# Post-process the output\n",
    "predictions = torch.from_numpy(h_output).cpu().numpy()\n",
    "\n",
    "# Assuming the first class corresponds to 'cats' and the second to 'dogs'\n",
    "class_names = ['cats', 'dogs']\n",
    "predicted_class = np.argmax(predictions)\n",
    "\n",
    "# Print the predicted class and inference time\n",
    "print(\"Predicted class:\", class_names[predicted_class])\n",
    "print(\"Inference time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9dd542c-a04d-46ba-b2f8-fdb1b4487a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total FLOPs: 11632608\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load the pretrained ShuffleNet model\n",
    "model = models.shufflenet_v2_x1_0(pretrained=True)\n",
    "\n",
    "# Define input size (224x224x3) for ShuffleNet\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "# Function to calculate FLOPs for the model\n",
    "def count_flops(model, input_size):\n",
    "    # Define a tensor of appropriate size\n",
    "    input_tensor = torch.randn(1, *input_size)\n",
    "    \n",
    "    # Switch to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Move model to appropriate device\n",
    "    device = next(model.parameters()).device\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Iterate through model's layers\n",
    "    flops = 0\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            # For convolutional layers\n",
    "            output_size = (input_size[0] - module.kernel_size[0] + 2 * module.padding[0]) // module.stride[0] + 1\n",
    "            output_size = (output_size - module.kernel_size[1] + 2 * module.padding[1]) // module.stride[1] + 1\n",
    "            flops += module.in_channels * module.out_channels * module.kernel_size[0] * module.kernel_size[1] * output_size * output_size\n",
    "            input_size = (output_size, output_size, module.out_channels)\n",
    "        elif isinstance(module, torch.nn.Linear):\n",
    "            # For fully connected layers\n",
    "            flops += module.in_features * module.out_features\n",
    "            input_size = (module.out_features,)\n",
    "    \n",
    "    return flops\n",
    "\n",
    "# Calculate FLOPs\n",
    "total_flops = count_flops(model, input_size)\n",
    "print(\"Total FLOPs:\", total_flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a29e735-34a5-40a1-b8de-50aaa6d942eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 2278604\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total trainable parameters: {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81cde74-6027-473b-b168-430cda81bd7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
