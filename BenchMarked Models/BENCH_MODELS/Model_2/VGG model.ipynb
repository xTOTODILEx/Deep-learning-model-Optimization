{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71dbed02-06e1-45b8-95b1-ea3fd96f0510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
      "95.9%"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# Load the pre-trained VGG model\n",
    "model = models.vgg19(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "867a53b0-1b7d-477a-a051-a175aeeec481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): ReLU(inplace=True)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): ReLU(inplace=True)\n",
      "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (33): ReLU(inplace=True)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7616a655-14e0-4859-a17d-251867d63551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Dogs\n",
      "Inference time: 2.8739 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.models import vgg19\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "# Load the pre-trained VGG-19 model\n",
    "model = vgg19(pretrained=True)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Load and preprocess an example image\n",
    "image_path = '1.jpg'\n",
    "input_image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "# Define the image transformation pipeline\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Apply transformations to the input image\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)  # Add a batch dimension\n",
    "\n",
    "# Make the prediction\n",
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    output = model(input_batch)\n",
    "    end_time = time.time()\n",
    "\n",
    "# Get the predicted class index\n",
    "_, predicted_idx = torch.max(output, 1)\n",
    "predicted_class = \"Cats\" if predicted_idx.item() == 0 else \"Dogs\"\n",
    "\n",
    "# Print the predicted class label and inference time\n",
    "inference_time = end_time - start_time\n",
    "print(f'Predicted class: {predicted_class}')\n",
    "print(f'Inference time: {inference_time:.4f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ab726b3-9eea-409e-b2aa-ee27980621b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input.1 : Float(1, 3, 224, 224, strides=[150528, 50176, 224, 1], requires_grad=0, device=cpu),\n",
      "      %features.0.weight : Float(64, 3, 3, 3, strides=[27, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.0.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.2.weight : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.2.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.5.weight : Float(128, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.5.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.7.weight : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.7.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.10.weight : Float(256, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.10.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.12.weight : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.12.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.14.weight : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.14.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.16.weight : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.16.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.19.weight : Float(512, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.19.bias : Float(512, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.21.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.21.bias : Float(512, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.23.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.23.bias : Float(512, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.25.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.25.bias : Float(512, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.28.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.28.bias : Float(512, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.30.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.30.bias : Float(512, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.32.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.32.bias : Float(512, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.34.weight : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.34.bias : Float(512, strides=[1], requires_grad=1, device=cpu),\n",
      "      %classifier.0.weight : Float(4096, 25088, strides=[25088, 1], requires_grad=1, device=cpu),\n",
      "      %classifier.0.bias : Float(4096, strides=[1], requires_grad=1, device=cpu),\n",
      "      %classifier.3.weight : Float(4096, 4096, strides=[4096, 1], requires_grad=1, device=cpu),\n",
      "      %classifier.3.bias : Float(4096, strides=[1], requires_grad=1, device=cpu),\n",
      "      %classifier.6.weight : Float(1000, 4096, strides=[4096, 1], requires_grad=1, device=cpu),\n",
      "      %classifier.6.bias : Float(1000, strides=[1], requires_grad=1, device=cpu)):\n",
      "  %39 : Float(1, 64, 224, 224, strides=[3211264, 50176, 224, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input.1, %features.0.weight, %features.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %40 : Float(1, 64, 224, 224, strides=[3211264, 50176, 224, 1], requires_grad=1, device=cpu) = onnx::Relu(%39) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %41 : Float(1, 64, 224, 224, strides=[3211264, 50176, 224, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%40, %features.2.weight, %features.2.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %42 : Float(1, 64, 224, 224, strides=[3211264, 50176, 224, 1], requires_grad=1, device=cpu) = onnx::Relu(%41) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %43 : Float(1, 64, 112, 112, strides=[802816, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%42) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:719:0\n",
      "  %44 : Float(1, 128, 112, 112, strides=[1605632, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%43, %features.5.weight, %features.5.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %45 : Float(1, 128, 112, 112, strides=[1605632, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::Relu(%44) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %46 : Float(1, 128, 112, 112, strides=[1605632, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%45, %features.7.weight, %features.7.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %47 : Float(1, 128, 112, 112, strides=[1605632, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::Relu(%46) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %48 : Float(1, 128, 56, 56, strides=[401408, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%47) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:719:0\n",
      "  %49 : Float(1, 256, 56, 56, strides=[802816, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%48, %features.10.weight, %features.10.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %50 : Float(1, 256, 56, 56, strides=[802816, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Relu(%49) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %51 : Float(1, 256, 56, 56, strides=[802816, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%50, %features.12.weight, %features.12.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %52 : Float(1, 256, 56, 56, strides=[802816, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Relu(%51) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %53 : Float(1, 256, 56, 56, strides=[802816, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%52, %features.14.weight, %features.14.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %54 : Float(1, 256, 56, 56, strides=[802816, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Relu(%53) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %55 : Float(1, 256, 56, 56, strides=[802816, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%54, %features.16.weight, %features.16.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %56 : Float(1, 256, 56, 56, strides=[802816, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Relu(%55) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %57 : Float(1, 256, 28, 28, strides=[200704, 784, 28, 1], requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%56) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:719:0\n",
      "  %58 : Float(1, 512, 28, 28, strides=[401408, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%57, %features.19.weight, %features.19.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %59 : Float(1, 512, 28, 28, strides=[401408, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Relu(%58) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %60 : Float(1, 512, 28, 28, strides=[401408, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%59, %features.21.weight, %features.21.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %61 : Float(1, 512, 28, 28, strides=[401408, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Relu(%60) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %62 : Float(1, 512, 28, 28, strides=[401408, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%61, %features.23.weight, %features.23.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %63 : Float(1, 512, 28, 28, strides=[401408, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Relu(%62) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %64 : Float(1, 512, 28, 28, strides=[401408, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%63, %features.25.weight, %features.25.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %65 : Float(1, 512, 28, 28, strides=[401408, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Relu(%64) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %66 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%65) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:719:0\n",
      "  %67 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%66, %features.28.weight, %features.28.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %68 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Relu(%67) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %69 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%68, %features.30.weight, %features.30.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %70 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Relu(%69) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %71 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%70, %features.32.weight, %features.32.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %72 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Relu(%71) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %73 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%72, %features.34.weight, %features.34.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %74 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Relu(%73) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %75 : Float(1, 512, 7, 7, strides=[25088, 49, 7, 1], requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%74) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:719:0\n",
      "  %76 : Float(1, 512, 7, 7, strides=[25088, 49, 7, 1], requires_grad=1, device=cpu) = onnx::AveragePool[kernel_shape=[1, 1], strides=[1, 1]](%75) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1131:0\n",
      "  %77 : Float(1, 25088, strides=[25088, 1], requires_grad=1, device=cpu) = onnx::Flatten[axis=1](%76) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/vgg.py:51:0\n",
      "  %78 : Float(1, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%77, %classifier.0.weight, %classifier.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1848:0\n",
      "  %79 : Float(1, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Relu(%78) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1169:0\n",
      "  %80 : Float(1, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%79, %classifier.3.weight, %classifier.3.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1848:0\n",
      "  %81 : Float(1, 4096, strides=[4096, 1], requires_grad=1, device=cpu) = onnx::Relu(%80) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1169:0\n",
      "  %82 : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%81, %classifier.6.weight, %classifier.6.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1848:0\n",
      "  return (%82)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.onnx\n",
    "\n",
    "# Load the pretrained VGG model\n",
    "model = models.vgg19(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Specify the input size\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Convert the PyTorch model to ONNX\n",
    "onnx_path = 'vgg19.onnx'\n",
    "torch.onnx.export(model, dummy_input, onnx_path, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4e06b20-8bba-4e6a-9ce2-8f213ab1c89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "559fceb0-c25c-4e1f-83d6-f327953536d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&& RUNNING TensorRT.trtexec [TensorRT v8201] # /usr/src/tensorrt/bin/trtexec --onnx=/nvdli-nano/data/Inference/MODELS/Model_2/vgg19.onnx --saveEngine=/nvdli-nano/data/Inference/MODELS/Model_2/vgg19.trt\n",
      "[02/08/2024-03:25:24] [I] === Model Options ===\n",
      "[02/08/2024-03:25:24] [I] Format: ONNX\n",
      "[02/08/2024-03:25:24] [I] Model: /nvdli-nano/data/Inference/MODELS/Model_2/vgg19.onnx\n",
      "[02/08/2024-03:25:24] [I] Output:\n",
      "[02/08/2024-03:25:24] [I] === Build Options ===\n",
      "[02/08/2024-03:25:24] [I] Max batch: explicit batch\n",
      "[02/08/2024-03:25:24] [I] Workspace: 16 MiB\n",
      "[02/08/2024-03:25:24] [I] minTiming: 1\n",
      "[02/08/2024-03:25:24] [I] avgTiming: 8\n",
      "[02/08/2024-03:25:24] [I] Precision: FP32\n",
      "[02/08/2024-03:25:24] [I] Calibration: \n",
      "[02/08/2024-03:25:24] [I] Refit: Disabled\n",
      "[02/08/2024-03:25:24] [I] Sparsity: Disabled\n",
      "[02/08/2024-03:25:24] [I] Safe mode: Disabled\n",
      "[02/08/2024-03:25:24] [I] DirectIO mode: Disabled\n",
      "[02/08/2024-03:25:24] [I] Restricted mode: Disabled\n",
      "[02/08/2024-03:25:24] [I] Save engine: /nvdli-nano/data/Inference/MODELS/Model_2/vgg19.trt\n",
      "[02/08/2024-03:25:24] [I] Load engine: \n",
      "[02/08/2024-03:25:24] [I] Profiling verbosity: 0\n",
      "[02/08/2024-03:25:24] [I] Tactic sources: Using default tactic sources\n",
      "[02/08/2024-03:25:24] [I] timingCacheMode: local\n",
      "[02/08/2024-03:25:24] [I] timingCacheFile: \n",
      "[02/08/2024-03:25:24] [I] Input(s)s format: fp32:CHW\n",
      "[02/08/2024-03:25:24] [I] Output(s)s format: fp32:CHW\n",
      "[02/08/2024-03:25:24] [I] Input build shapes: model\n",
      "[02/08/2024-03:25:24] [I] Input calibration shapes: model\n",
      "[02/08/2024-03:25:24] [I] === System Options ===\n",
      "[02/08/2024-03:25:24] [I] Device: 0\n",
      "[02/08/2024-03:25:24] [I] DLACore: \n",
      "[02/08/2024-03:25:24] [I] Plugins:\n",
      "[02/08/2024-03:25:24] [I] === Inference Options ===\n",
      "[02/08/2024-03:25:24] [I] Batch: Explicit\n",
      "[02/08/2024-03:25:24] [I] Input inference shapes: model\n",
      "[02/08/2024-03:25:24] [I] Iterations: 10\n",
      "[02/08/2024-03:25:24] [I] Duration: 3s (+ 200ms warm up)\n",
      "[02/08/2024-03:25:24] [I] Sleep time: 0ms\n",
      "[02/08/2024-03:25:24] [I] Idle time: 0ms\n",
      "[02/08/2024-03:25:24] [I] Streams: 1\n",
      "[02/08/2024-03:25:24] [I] ExposeDMA: Disabled\n",
      "[02/08/2024-03:25:24] [I] Data transfers: Enabled\n",
      "[02/08/2024-03:25:24] [I] Spin-wait: Disabled\n",
      "[02/08/2024-03:25:24] [I] Multithreading: Disabled\n",
      "[02/08/2024-03:25:24] [I] CUDA Graph: Disabled\n",
      "[02/08/2024-03:25:24] [I] Separate profiling: Disabled\n",
      "[02/08/2024-03:25:24] [I] Time Deserialize: Disabled\n",
      "[02/08/2024-03:25:24] [I] Time Refit: Disabled\n",
      "[02/08/2024-03:25:24] [I] Skip inference: Disabled\n",
      "[02/08/2024-03:25:24] [I] Inputs:\n",
      "[02/08/2024-03:25:24] [I] === Reporting Options ===\n",
      "[02/08/2024-03:25:24] [I] Verbose: Disabled\n",
      "[02/08/2024-03:25:24] [I] Averages: 10 inferences\n",
      "[02/08/2024-03:25:24] [I] Percentile: 99\n",
      "[02/08/2024-03:25:24] [I] Dump refittable layers:Disabled\n",
      "[02/08/2024-03:25:24] [I] Dump output: Disabled\n",
      "[02/08/2024-03:25:24] [I] Profile: Disabled\n",
      "[02/08/2024-03:25:24] [I] Export timing to JSON file: \n",
      "[02/08/2024-03:25:24] [I] Export output to JSON file: \n",
      "[02/08/2024-03:25:24] [I] Export profile to JSON file: \n",
      "[02/08/2024-03:25:24] [I] \n",
      "[02/08/2024-03:25:24] [I] === Device Information ===\n",
      "[02/08/2024-03:25:24] [I] Selected Device: NVIDIA Tegra X1\n",
      "[02/08/2024-03:25:24] [I] Compute Capability: 5.3\n",
      "[02/08/2024-03:25:24] [I] SMs: 1\n",
      "[02/08/2024-03:25:24] [I] Compute Clock Rate: 0.9216 GHz\n",
      "[02/08/2024-03:25:24] [I] Device Global Memory: 3956 MiB\n",
      "[02/08/2024-03:25:24] [I] Shared Memory per SM: 64 KiB\n",
      "[02/08/2024-03:25:24] [I] Memory Bus Width: 64 bits (ECC disabled)\n",
      "[02/08/2024-03:25:24] [I] Memory Clock Rate: 0.01275 GHz\n",
      "[02/08/2024-03:25:24] [I] \n",
      "[02/08/2024-03:25:24] [I] TensorRT version: 8.2.1\n",
      "[02/08/2024-03:25:27] [I] [TRT] [MemUsageChange] Init CUDA: CPU +229, GPU +0, now: CPU 248, GPU 2714 (MiB)\n",
      "[02/08/2024-03:25:28] [I] [TRT] [MemUsageSnapshot] Begin constructing builder kernel library: CPU 248 MiB, GPU 2745 MiB\n",
      "[02/08/2024-03:25:28] [I] [TRT] [MemUsageSnapshot] End constructing builder kernel library: CPU 277 MiB, GPU 2744 MiB\n",
      "[02/08/2024-03:25:28] [I] Start parsing network model\n",
      "[libprotobuf WARNING google/protobuf/io/coded_stream.cc:604] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n",
      "[libprotobuf WARNING google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 574851337\n",
      "[02/08/2024-03:25:34] [I] [TRT] ----------------------------------------------------------------\n",
      "[02/08/2024-03:25:34] [I] [TRT] Input filename:   /nvdli-nano/data/Inference/MODELS/Model_2/vgg19.onnx\n",
      "[02/08/2024-03:25:34] [I] [TRT] ONNX IR version:  0.0.7\n",
      "[02/08/2024-03:25:34] [I] [TRT] Opset version:    9\n",
      "[02/08/2024-03:25:34] [I] [TRT] Producer name:    pytorch\n",
      "[02/08/2024-03:25:34] [I] [TRT] Producer version: 1.10\n",
      "[02/08/2024-03:25:34] [I] [TRT] Domain:           \n",
      "[02/08/2024-03:25:34] [I] [TRT] Model version:    0\n",
      "[02/08/2024-03:25:34] [I] [TRT] Doc string:       \n",
      "[02/08/2024-03:25:34] [I] [TRT] ----------------------------------------------------------------\n",
      "[libprotobuf WARNING google/protobuf/io/coded_stream.cc:604] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n",
      "[libprotobuf WARNING google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 574851337\n",
      "[02/08/2024-03:25:41] [I] Finish parsing network model\n",
      "[02/08/2024-03:25:41] [I] [TRT] ---------- Layers Running on DLA ----------\n",
      "[02/08/2024-03:25:41] [I] [TRT] ---------- Layers Running on GPU ----------\n",
      "[02/08/2024-03:25:41] [I] [TRT] [GpuLayer] Conv_0 + Relu_1\n",
      "[02/08/2024-03:25:41] [I] [TRT] [GpuLayer] Conv_2 + Relu_3\n",
      "[02/08/2024-03:25:41] [I] [TRT] [GpuLayer] MaxPool_4\n",
      "[02/08/2024-03:25:41] [I] [TRT] [GpuLayer] Conv_5 + Relu_6\n",
      "[02/08/2024-03:25:41] [I] [TRT] [GpuLayer] Conv_7 + Relu_8\n",
      "[02/08/2024-03:25:41] [I] [TRT] [GpuLayer] MaxPool_9\n",
      "[02/08/2024-03:25:41] [I] [TRT] [GpuLayer] Conv_10 + Relu_11\n",
      "[02/08/2024-03:25:41] [I] [TRT] [GpuLayer] Conv_12 + Relu_13\n",
      "[02/08/2024-03:25:41] [I] [TRT] [GpuLayer] Conv_14 + Relu_15\n",
      "[02/08/2024-03:25:41] [I] [TRT] [GpuLayer] Conv_16 + Relu_17\n",
      "[02/08/2024-03:25:41] [I] [TRT] [GpuLayer] MaxPool_18\n",
      "[02/08/2024-03:25:41] [I] [TRT] [GpuLayer] Conv_19 + Relu_20\n",
      "[02/08/2024-03:25:41] [I] [TRT] [GpuLayer] Conv_21 + Relu_22\n",
      "[02/08/2024-03:25:41] [I] [TRT] [GpuLayer] Conv_23 + Relu_24\n",
      "[02/08/2024-03:25:41] [I] [TRT] [GpuLayer] Conv_25 + Relu_26\n",
      "[02/08/2024-03:25:41] [I] [TRT] [GpuLayer] MaxPool_27\n",
      "[02/08/2024-03:25:41] [I] [TRT] [GpuLayer] Conv_28 + Relu_29\n",
      "[02/08/2024-03:25:41] [I] [TRT] [GpuLayer] Conv_30 + Relu_31\n",
      "[02/08/2024-03:25:41] [I] [TRT] [GpuLayer] Conv_32 + Relu_33\n",
      "[02/08/2024-03:25:41] [I] [TRT] [GpuLayer] Conv_34 + Relu_35\n",
      "[02/08/2024-03:25:41] [I] [TRT] [GpuLayer] MaxPool_36\n",
      "[02/08/2024-03:25:41] [I] [TRT] [GpuLayer] AveragePool_37\n",
      "[02/08/2024-03:25:41] [I] [TRT] [GpuLayer] Flatten_38 + (Unnamed Layer* 39) [Shuffle]\n",
      "[02/08/2024-03:25:41] [I] [TRT] [GpuLayer] Gemm_39 + Relu_40\n",
      "[02/08/2024-03:25:41] [I] [TRT] [GpuLayer] Gemm_41 + Relu_42\n",
      "[02/08/2024-03:25:41] [I] [TRT] [GpuLayer] Gemm_43\n",
      "[02/08/2024-03:25:41] [I] [TRT] [GpuLayer] (Unnamed Layer* 49) [Shuffle]\n",
      "[02/08/2024-03:25:44] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +158, GPU +272, now: CPU 984, GPU 3016 (MiB)\n",
      "[02/08/2024-03:25:47] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +241, GPU +418, now: CPU 1225, GPU 3434 (MiB)\n",
      "[02/08/2024-03:25:47] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[02/08/2024-03:25:56] [I] [TRT] Some tactics do not have sufficient workspace memory to run. Increasing workspace size may increase performance, please check verbose output.\n",
      "[02/08/2024-03:30:25] [I] [TRT] Detected 1 inputs and 1 output network tensors.\n",
      "[02/08/2024-03:30:50] [I] [TRT] Total Host Persistent Memory: 10496\n",
      "[02/08/2024-03:30:50] [I] [TRT] Total Device Persistent Memory: 222743552\n",
      "[02/08/2024-03:30:50] [I] [TRT] Total Scratch Memory: 0\n",
      "[02/08/2024-03:30:50] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 392 MiB, GPU 1280 MiB\n",
      "[02/08/2024-03:30:50] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 0.767673ms to assign 3 blocks to 26 nodes requiring 25690113 bytes.\n",
      "[02/08/2024-03:30:50] [I] [TRT] Total Activation Memory: 25690113\n",
      "[02/08/2024-03:30:50] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +16, now: CPU 1484, GPU 3860 (MiB)\n",
      "[02/08/2024-03:30:50] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +9, now: CPU 1484, GPU 3869 (MiB)\n",
      "[02/08/2024-03:30:50] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +1024, now: CPU 0, GPU 1024 (MiB)\n",
      "[02/08/2024-03:31:17] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 2167, GPU 2912 (MiB)\n",
      "[02/08/2024-03:31:18] [I] [TRT] Loaded engine size: 684 MiB\n",
      "[02/08/2024-03:31:20] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +14, now: CPU 2168, GPU 3639 (MiB)\n",
      "[02/08/2024-03:31:20] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +10, now: CPU 2168, GPU 3649 (MiB)\n",
      "[02/08/2024-03:31:21] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +684, now: CPU 0, GPU 684 (MiB)\n",
      "[02/08/2024-03:31:40] [I] Engine built in 376.439 sec.\n",
      "[02/08/2024-03:31:42] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +1, now: CPU 906, GPU 2685 (MiB)\n",
      "[02/08/2024-03:31:42] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +5, now: CPU 906, GPU 2690 (MiB)\n",
      "[02/08/2024-03:31:42] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +237, now: CPU 0, GPU 921 (MiB)\n",
      "[02/08/2024-03:31:42] [I] Using random values for input input.1\n",
      "[02/08/2024-03:31:42] [I] Created input binding for input.1 with dimensions 1x3x224x224\n",
      "[02/08/2024-03:31:42] [I] Using random values for output 82\n",
      "[02/08/2024-03:31:42] [I] Created output binding for 82 with dimensions 1x1000\n",
      "[02/08/2024-03:31:42] [I] Starting inference\n",
      "[02/08/2024-03:31:46] [I] Warmup completed 1 queries over 200 ms\n",
      "[02/08/2024-03:31:46] [I] Timing trace has 11 queries over 3.09735 s\n",
      "[02/08/2024-03:31:46] [I] \n",
      "[02/08/2024-03:31:46] [I] === Trace details ===\n",
      "[02/08/2024-03:31:46] [I] Trace averages of 10 runs:\n",
      "[02/08/2024-03:31:46] [I] Average on 10 runs - GPU latency: 281.814 ms - Host latency: 281.874 ms (end to end 281.884 ms, enqueue 13.3008 ms)\n",
      "[02/08/2024-03:31:46] [I] \n",
      "[02/08/2024-03:31:46] [I] === Performance summary ===\n",
      "[02/08/2024-03:31:46] [I] Throughput: 3.55142 qps\n",
      "[02/08/2024-03:31:46] [I] Latency: min = 278.306 ms, max = 284.787 ms, mean = 281.567 ms, median = 281.412 ms, percentile(99%) = 284.787 ms\n",
      "[02/08/2024-03:31:46] [I] End-to-End Host Latency: min = 278.317 ms, max = 284.797 ms, mean = 281.577 ms, median = 281.421 ms, percentile(99%) = 284.797 ms\n",
      "[02/08/2024-03:31:46] [I] Enqueue Time: min = 3.7002 ms, max = 33.8981 ms, mean = 12.6181 ms, median = 6.63965 ms, percentile(99%) = 33.8981 ms\n",
      "[02/08/2024-03:31:46] [I] H2D Latency: min = 0.0559082 ms, max = 0.0588379 ms, mean = 0.0574285 ms, median = 0.0576172 ms, percentile(99%) = 0.0588379 ms\n",
      "[02/08/2024-03:31:46] [I] GPU Compute Time: min = 278.245 ms, max = 284.728 ms, mean = 281.507 ms, median = 281.353 ms, percentile(99%) = 284.728 ms\n",
      "[02/08/2024-03:31:46] [I] D2H Latency: min = 0.00170898 ms, max = 0.00341797 ms, mean = 0.00287975 ms, median = 0.00292969 ms, percentile(99%) = 0.00341797 ms\n",
      "[02/08/2024-03:31:46] [I] Total Host Walltime: 3.09735 s\n",
      "[02/08/2024-03:31:46] [I] Total GPU Compute Time: 3.09658 s\n",
      "[02/08/2024-03:31:46] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
      "[02/08/2024-03:31:46] [I] \n",
      "&&&& PASSED TensorRT.trtexec [TensorRT v8201] # /usr/src/tensorrt/bin/trtexec --onnx=/nvdli-nano/data/Inference/MODELS/Model_2/vgg19.onnx --saveEngine=/nvdli-nano/data/Inference/MODELS/Model_2/vgg19.trt\n"
     ]
    }
   ],
   "source": [
    "!/usr/src/tensorrt/bin/trtexec --onnx=/nvdli-nano/data/Inference/MODELS/Model_2/vgg19.onnx --saveEngine=/nvdli-nano/data/Inference/MODELS/Model_2/vgg19.trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "674ea131-b09e-4380-aa0d-aa6e638c44f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: dogs\n",
      "Inference time: 0.42856812477111816 seconds\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorrt as trt\n",
    "import time\n",
    "\n",
    "# Load the TensorRT model\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "with open('vgg19.trt', 'rb') as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "    engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "# Load and preprocess the input image\n",
    "image_path = '1.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.resize(image, (224, 224))\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "image = image.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
    "image = np.transpose(image, (2, 0, 1))  # Change to channel-first format\n",
    "\n",
    "# Convert to torch tensor\n",
    "image_tensor = torch.tensor(image, dtype=torch.float32)\n",
    "\n",
    "# Run inference and measure time\n",
    "with torch.no_grad():\n",
    "    # Convert the tensor to a batched format\n",
    "    input_data = image_tensor.unsqueeze(0)\n",
    "\n",
    "    # Transfer the input tensor to GPU (if available)\n",
    "    if torch.cuda.is_available():\n",
    "        input_data = input_data.to('cuda')\n",
    "\n",
    "    # Allocate device memory for the input tensor\n",
    "    d_input = torch.cuda.FloatTensor(input_data)\n",
    "\n",
    "    # Allocate device memory for the output tensor\n",
    "    d_output = torch.empty((1, 2), device='cuda')  # Assuming 2 classes (dogs and cats)\n",
    "\n",
    "    # Measure inference time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Run inference\n",
    "    context.execute(1, bindings=[int(d_input.data_ptr()), int(d_output.data_ptr())])\n",
    "\n",
    "    # Measure elapsed time\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    # Transfer the output tensor back to the host\n",
    "    h_output = d_output.cpu().numpy()\n",
    "\n",
    "# Post-process the output\n",
    "predictions = torch.from_numpy(h_output).cpu().numpy()\n",
    "\n",
    "# Assuming the first class corresponds to 'cats' and the second to 'dogs'\n",
    "class_names = ['cats', 'dogs']\n",
    "predicted_class = np.argmax(predictions)\n",
    "\n",
    "# Print the predicted class and inference time\n",
    "print(\"Predicted class:\", class_names[predicted_class])\n",
    "print(\"Inference time:\", elapsed_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "820a18b4-8d77-41f3-98c3-d851a47e347b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 143667240\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total trainable parameters: {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91222d7e-3816-4df0-ac34-56805a475e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total FLOPs: 1004590956544\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load the pretrained VGG-19 model\n",
    "model = models.vgg19(pretrained=True)\n",
    "\n",
    "# Define input size (224x224x3) for VGG-19\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "# Function to calculate FLOPs for the model\n",
    "def count_flops(model, input_size):\n",
    "    # Define a tensor of appropriate size\n",
    "    input_tensor = torch.randn(1, *input_size)\n",
    "    \n",
    "    # Switch to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Move model to appropriate device\n",
    "    device = next(model.parameters()).device\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Iterate through model's layers\n",
    "    flops = 0\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            # For convolutional layers\n",
    "            output_size = (input_size[0] - module.kernel_size[0] + 2 * module.padding[0]) // module.stride[0] + 1\n",
    "            output_size = (output_size - module.kernel_size[1] + 2 * module.padding[1]) // module.stride[1] + 1\n",
    "            flops += module.in_channels * module.out_channels * module.kernel_size[0] * module.kernel_size[1] * output_size * output_size\n",
    "            input_size = (output_size, output_size, module.out_channels)\n",
    "        elif isinstance(module, torch.nn.Linear):\n",
    "            # For fully connected layers\n",
    "            flops += module.in_features * module.out_features\n",
    "            input_size = (module.out_features,)\n",
    "    \n",
    "    return flops\n",
    "\n",
    "# Calculate FLOPs\n",
    "total_flops = count_flops(model, input_size)\n",
    "print(\"Total FLOPs:\", total_flops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63d7011-79d6-423a-8d65-78694112b5d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
