{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eb66aa8-6281-47bf-9228-df1d6fb80cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# Load the pre-trained MobileNet model\n",
    "model = models.mobilenet_v2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c4d3a31-4d19-402c-9395-498969ee3a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2(\n",
      "  (features): Sequential(\n",
      "    (0): ConvNormActivation(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): ConvNormActivation(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27908fd5-7237-4eeb-b573-311e1207d668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Dogs\n",
      "Inference time: 5.0379 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.models import mobilenet_v2\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "# Load the pre-trained MobileNet V2 model\n",
    "model = mobilenet_v2(pretrained=True)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Load and preprocess an example image\n",
    "image_path = '1.jpg'\n",
    "input_image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "# Define the image transformation pipeline\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Apply transformations to the input image\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)  # Add a batch dimension\n",
    "\n",
    "# Make the prediction\n",
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    output = model(input_batch)\n",
    "    end_time = time.time()\n",
    "\n",
    "# Get the predicted class index\n",
    "_, predicted_idx = torch.max(output, 1)\n",
    "predicted_class = \"Cats\" if predicted_idx.item() == 0 else \"Dogs\"\n",
    "\n",
    "# Print the predicted class label and inference time\n",
    "inference_time = end_time - start_time\n",
    "print(f'Predicted class: {predicted_class}')\n",
    "print(f'Inference time: {inference_time:.4f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b6911a5-7782-4100-b49c-eee36ef8029f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input.1 : Float(1, 3, 224, 224, strides=[150528, 50176, 224, 1], requires_grad=0, device=cpu),\n",
      "      %classifier.1.weight : Float(1000, 1280, strides=[1280, 1], requires_grad=1, device=cpu),\n",
      "      %classifier.1.bias : Float(1000, strides=[1], requires_grad=1, device=cpu),\n",
      "      %468 : Float(32, 3, 3, 3, strides=[27, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %469 : Float(32, strides=[1], requires_grad=0, device=cpu),\n",
      "      %471 : Float(32, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %472 : Float(32, strides=[1], requires_grad=0, device=cpu),\n",
      "      %474 : Float(16, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %475 : Float(16, strides=[1], requires_grad=0, device=cpu),\n",
      "      %477 : Float(96, 16, 1, 1, strides=[16, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %478 : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %480 : Float(96, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %481 : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %483 : Float(24, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %484 : Float(24, strides=[1], requires_grad=0, device=cpu),\n",
      "      %486 : Float(144, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %487 : Float(144, strides=[1], requires_grad=0, device=cpu),\n",
      "      %489 : Float(144, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %490 : Float(144, strides=[1], requires_grad=0, device=cpu),\n",
      "      %492 : Float(24, 144, 1, 1, strides=[144, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %493 : Float(24, strides=[1], requires_grad=0, device=cpu),\n",
      "      %495 : Float(144, 24, 1, 1, strides=[24, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %496 : Float(144, strides=[1], requires_grad=0, device=cpu),\n",
      "      %498 : Float(144, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %499 : Float(144, strides=[1], requires_grad=0, device=cpu),\n",
      "      %501 : Float(32, 144, 1, 1, strides=[144, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %502 : Float(32, strides=[1], requires_grad=0, device=cpu),\n",
      "      %504 : Float(192, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %505 : Float(192, strides=[1], requires_grad=0, device=cpu),\n",
      "      %507 : Float(192, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %508 : Float(192, strides=[1], requires_grad=0, device=cpu),\n",
      "      %510 : Float(32, 192, 1, 1, strides=[192, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %511 : Float(32, strides=[1], requires_grad=0, device=cpu),\n",
      "      %513 : Float(192, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %514 : Float(192, strides=[1], requires_grad=0, device=cpu),\n",
      "      %516 : Float(192, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %517 : Float(192, strides=[1], requires_grad=0, device=cpu),\n",
      "      %519 : Float(32, 192, 1, 1, strides=[192, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %520 : Float(32, strides=[1], requires_grad=0, device=cpu),\n",
      "      %522 : Float(192, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %523 : Float(192, strides=[1], requires_grad=0, device=cpu),\n",
      "      %525 : Float(192, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %526 : Float(192, strides=[1], requires_grad=0, device=cpu),\n",
      "      %528 : Float(64, 192, 1, 1, strides=[192, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %529 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %531 : Float(384, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %532 : Float(384, strides=[1], requires_grad=0, device=cpu),\n",
      "      %534 : Float(384, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %535 : Float(384, strides=[1], requires_grad=0, device=cpu),\n",
      "      %537 : Float(64, 384, 1, 1, strides=[384, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %538 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %540 : Float(384, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %541 : Float(384, strides=[1], requires_grad=0, device=cpu),\n",
      "      %543 : Float(384, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %544 : Float(384, strides=[1], requires_grad=0, device=cpu),\n",
      "      %546 : Float(64, 384, 1, 1, strides=[384, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %547 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %549 : Float(384, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %550 : Float(384, strides=[1], requires_grad=0, device=cpu),\n",
      "      %552 : Float(384, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %553 : Float(384, strides=[1], requires_grad=0, device=cpu),\n",
      "      %555 : Float(64, 384, 1, 1, strides=[384, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %556 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %558 : Float(384, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %559 : Float(384, strides=[1], requires_grad=0, device=cpu),\n",
      "      %561 : Float(384, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %562 : Float(384, strides=[1], requires_grad=0, device=cpu),\n",
      "      %564 : Float(96, 384, 1, 1, strides=[384, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %565 : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %567 : Float(576, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %568 : Float(576, strides=[1], requires_grad=0, device=cpu),\n",
      "      %570 : Float(576, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %571 : Float(576, strides=[1], requires_grad=0, device=cpu),\n",
      "      %573 : Float(96, 576, 1, 1, strides=[576, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %574 : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %576 : Float(576, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %577 : Float(576, strides=[1], requires_grad=0, device=cpu),\n",
      "      %579 : Float(576, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %580 : Float(576, strides=[1], requires_grad=0, device=cpu),\n",
      "      %582 : Float(96, 576, 1, 1, strides=[576, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %583 : Float(96, strides=[1], requires_grad=0, device=cpu),\n",
      "      %585 : Float(576, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %586 : Float(576, strides=[1], requires_grad=0, device=cpu),\n",
      "      %588 : Float(576, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %589 : Float(576, strides=[1], requires_grad=0, device=cpu),\n",
      "      %591 : Float(160, 576, 1, 1, strides=[576, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %592 : Float(160, strides=[1], requires_grad=0, device=cpu),\n",
      "      %594 : Float(960, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %595 : Float(960, strides=[1], requires_grad=0, device=cpu),\n",
      "      %597 : Float(960, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %598 : Float(960, strides=[1], requires_grad=0, device=cpu),\n",
      "      %600 : Float(160, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %601 : Float(160, strides=[1], requires_grad=0, device=cpu),\n",
      "      %603 : Float(960, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %604 : Float(960, strides=[1], requires_grad=0, device=cpu),\n",
      "      %606 : Float(960, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %607 : Float(960, strides=[1], requires_grad=0, device=cpu),\n",
      "      %609 : Float(160, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %610 : Float(160, strides=[1], requires_grad=0, device=cpu),\n",
      "      %612 : Float(960, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %613 : Float(960, strides=[1], requires_grad=0, device=cpu),\n",
      "      %615 : Float(960, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %616 : Float(960, strides=[1], requires_grad=0, device=cpu),\n",
      "      %618 : Float(320, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %619 : Float(320, strides=[1], requires_grad=0, device=cpu),\n",
      "      %621 : Float(1280, 320, 1, 1, strides=[320, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %622 : Float(1280, strides=[1], requires_grad=0, device=cpu)):\n",
      "  %467 : Float(1, 32, 112, 112, strides=[401408, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%input.1, %468, %469)\n",
      "  %317 : Float(1, 32, 112, 112, strides=[401408, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%467) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %470 : Float(1, 32, 112, 112, strides=[401408, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=32, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%317, %471, %472)\n",
      "  %320 : Float(1, 32, 112, 112, strides=[401408, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%470) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %473 : Float(1, 16, 112, 112, strides=[200704, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%320, %474, %475)\n",
      "  %476 : Float(1, 96, 112, 112, strides=[1204224, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%473, %477, %478)\n",
      "  %325 : Float(1, 96, 112, 112, strides=[1204224, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%476) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %479 : Float(1, 96, 56, 56, strides=[301056, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=96, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%325, %480, %481)\n",
      "  %328 : Float(1, 96, 56, 56, strides=[301056, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%479) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %482 : Float(1, 24, 56, 56, strides=[75264, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%328, %483, %484)\n",
      "  %485 : Float(1, 144, 56, 56, strides=[451584, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%482, %486, %487)\n",
      "  %333 : Float(1, 144, 56, 56, strides=[451584, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%485) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %488 : Float(1, 144, 56, 56, strides=[451584, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=144, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%333, %489, %490)\n",
      "  %336 : Float(1, 144, 56, 56, strides=[451584, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%488) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %491 : Float(1, 24, 56, 56, strides=[75264, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%336, %492, %493)\n",
      "  %339 : Float(1, 24, 56, 56, strides=[75264, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Add(%482, %491) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/mobilenetv2.py:76:0\n",
      "  %494 : Float(1, 144, 56, 56, strides=[451584, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%339, %495, %496)\n",
      "  %342 : Float(1, 144, 56, 56, strides=[451584, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%494) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %497 : Float(1, 144, 28, 28, strides=[112896, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=144, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%342, %498, %499)\n",
      "  %345 : Float(1, 144, 28, 28, strides=[112896, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%497) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %500 : Float(1, 32, 28, 28, strides=[25088, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%345, %501, %502)\n",
      "  %503 : Float(1, 192, 28, 28, strides=[150528, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%500, %504, %505)\n",
      "  %350 : Float(1, 192, 28, 28, strides=[150528, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%503) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %506 : Float(1, 192, 28, 28, strides=[150528, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=192, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%350, %507, %508)\n",
      "  %353 : Float(1, 192, 28, 28, strides=[150528, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%506) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %509 : Float(1, 32, 28, 28, strides=[25088, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%353, %510, %511)\n",
      "  %356 : Float(1, 32, 28, 28, strides=[25088, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Add(%500, %509) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/mobilenetv2.py:76:0\n",
      "  %512 : Float(1, 192, 28, 28, strides=[150528, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%356, %513, %514)\n",
      "  %359 : Float(1, 192, 28, 28, strides=[150528, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%512) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %515 : Float(1, 192, 28, 28, strides=[150528, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=192, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%359, %516, %517)\n",
      "  %362 : Float(1, 192, 28, 28, strides=[150528, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%515) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %518 : Float(1, 32, 28, 28, strides=[25088, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%362, %519, %520)\n",
      "  %365 : Float(1, 32, 28, 28, strides=[25088, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Add(%356, %518) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/mobilenetv2.py:76:0\n",
      "  %521 : Float(1, 192, 28, 28, strides=[150528, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%365, %522, %523)\n",
      "  %368 : Float(1, 192, 28, 28, strides=[150528, 784, 28, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%521) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %524 : Float(1, 192, 14, 14, strides=[37632, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=192, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%368, %525, %526)\n",
      "  %371 : Float(1, 192, 14, 14, strides=[37632, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%524) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %527 : Float(1, 64, 14, 14, strides=[12544, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%371, %528, %529)\n",
      "  %530 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%527, %531, %532)\n",
      "  %376 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%530) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %533 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%376, %534, %535)\n",
      "  %379 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%533) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %536 : Float(1, 64, 14, 14, strides=[12544, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%379, %537, %538)\n",
      "  %382 : Float(1, 64, 14, 14, strides=[12544, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Add(%527, %536) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/mobilenetv2.py:76:0\n",
      "  %539 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%382, %540, %541)\n",
      "  %385 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%539) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %542 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%385, %543, %544)\n",
      "  %388 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%542) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %545 : Float(1, 64, 14, 14, strides=[12544, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%388, %546, %547)\n",
      "  %391 : Float(1, 64, 14, 14, strides=[12544, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Add(%382, %545) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/mobilenetv2.py:76:0\n",
      "  %548 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%391, %549, %550)\n",
      "  %394 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%548) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %551 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%394, %552, %553)\n",
      "  %397 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%551) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %554 : Float(1, 64, 14, 14, strides=[12544, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%397, %555, %556)\n",
      "  %400 : Float(1, 64, 14, 14, strides=[12544, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Add(%391, %554) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/mobilenetv2.py:76:0\n",
      "  %557 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%400, %558, %559)\n",
      "  %403 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%557) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %560 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=384, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%403, %561, %562)\n",
      "  %406 : Float(1, 384, 14, 14, strides=[75264, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%560) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %563 : Float(1, 96, 14, 14, strides=[18816, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%406, %564, %565)\n",
      "  %566 : Float(1, 576, 14, 14, strides=[112896, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%563, %567, %568)\n",
      "  %411 : Float(1, 576, 14, 14, strides=[112896, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%566) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %569 : Float(1, 576, 14, 14, strides=[112896, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=576, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%411, %570, %571)\n",
      "  %414 : Float(1, 576, 14, 14, strides=[112896, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%569) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %572 : Float(1, 96, 14, 14, strides=[18816, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%414, %573, %574)\n",
      "  %417 : Float(1, 96, 14, 14, strides=[18816, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Add(%563, %572) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/mobilenetv2.py:76:0\n",
      "  %575 : Float(1, 576, 14, 14, strides=[112896, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%417, %576, %577)\n",
      "  %420 : Float(1, 576, 14, 14, strides=[112896, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%575) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %578 : Float(1, 576, 14, 14, strides=[112896, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=576, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%420, %579, %580)\n",
      "  %423 : Float(1, 576, 14, 14, strides=[112896, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%578) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %581 : Float(1, 96, 14, 14, strides=[18816, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%423, %582, %583)\n",
      "  %426 : Float(1, 96, 14, 14, strides=[18816, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Add(%417, %581) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/mobilenetv2.py:76:0\n",
      "  %584 : Float(1, 576, 14, 14, strides=[112896, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%426, %585, %586)\n",
      "  %429 : Float(1, 576, 14, 14, strides=[112896, 196, 14, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%584) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %587 : Float(1, 576, 7, 7, strides=[28224, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=576, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%429, %588, %589)\n",
      "  %432 : Float(1, 576, 7, 7, strides=[28224, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%587) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %590 : Float(1, 160, 7, 7, strides=[7840, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%432, %591, %592)\n",
      "  %593 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%590, %594, %595)\n",
      "  %437 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%593) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %596 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%437, %597, %598)\n",
      "  %440 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%596) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %599 : Float(1, 160, 7, 7, strides=[7840, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%440, %600, %601)\n",
      "  %443 : Float(1, 160, 7, 7, strides=[7840, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Add(%590, %599) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/mobilenetv2.py:76:0\n",
      "  %602 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%443, %603, %604)\n",
      "  %446 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%602) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %605 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%446, %606, %607)\n",
      "  %449 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%605) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %608 : Float(1, 160, 7, 7, strides=[7840, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%449, %609, %610)\n",
      "  %452 : Float(1, 160, 7, 7, strides=[7840, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Add(%443, %608) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/mobilenetv2.py:76:0\n",
      "  %611 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%452, %612, %613)\n",
      "  %455 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%611) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %614 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%455, %615, %616)\n",
      "  %458 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%614) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %617 : Float(1, 320, 7, 7, strides=[15680, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%458, %618, %619)\n",
      "  %620 : Float(1, 1280, 7, 7, strides=[62720, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%617, %621, %622)\n",
      "  %463 : Float(1, 1280, 7, 7, strides=[62720, 49, 7, 1], requires_grad=1, device=cpu) = onnx::Clip[max=6., min=0.](%620) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1348:0\n",
      "  %464 : Float(1, 1280, 1, 1, strides=[1280, 1, 1, 1], requires_grad=1, device=cpu) = onnx::GlobalAveragePool(%463) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1131:0\n",
      "  %465 : Float(1, 1280, strides=[1280, 1], requires_grad=1, device=cpu) = onnx::Flatten[axis=1](%464) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1169:0\n",
      "  %466 : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%465, %classifier.1.weight, %classifier.1.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1848:0\n",
      "  return (%466)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.onnx\n",
    "\n",
    "# Load the pre-trained MobileNet model\n",
    "model = models.mobilenet_v2(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Specify the input size\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Convert the PyTorch model to ONNX\n",
    "onnx_path = 'mobilenet.onnx'\n",
    "torch.onnx.export(model, dummy_input, onnx_path, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "111224f7-0b95-4308-9f3b-a88d509c861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "533dcf30-a61d-45d4-bddd-4865ff5ddf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&& RUNNING TensorRT.trtexec [TensorRT v8201] # /usr/src/tensorrt/bin/trtexec --onnx=/nvdli-nano/data/Inference/MODELS/Model_7/mobilenet.onnx --saveEngine=/nvdli-nano/data/Inference/MODELS/Model_7/mobilenet.trt\n",
      "[02/08/2024-06:22:33] [I] === Model Options ===\n",
      "[02/08/2024-06:22:33] [I] Format: ONNX\n",
      "[02/08/2024-06:22:33] [I] Model: /nvdli-nano/data/Inference/MODELS/Model_7/mobilenet.onnx\n",
      "[02/08/2024-06:22:33] [I] Output:\n",
      "[02/08/2024-06:22:33] [I] === Build Options ===\n",
      "[02/08/2024-06:22:33] [I] Max batch: explicit batch\n",
      "[02/08/2024-06:22:33] [I] Workspace: 16 MiB\n",
      "[02/08/2024-06:22:33] [I] minTiming: 1\n",
      "[02/08/2024-06:22:33] [I] avgTiming: 8\n",
      "[02/08/2024-06:22:33] [I] Precision: FP32\n",
      "[02/08/2024-06:22:33] [I] Calibration: \n",
      "[02/08/2024-06:22:33] [I] Refit: Disabled\n",
      "[02/08/2024-06:22:33] [I] Sparsity: Disabled\n",
      "[02/08/2024-06:22:33] [I] Safe mode: Disabled\n",
      "[02/08/2024-06:22:33] [I] DirectIO mode: Disabled\n",
      "[02/08/2024-06:22:33] [I] Restricted mode: Disabled\n",
      "[02/08/2024-06:22:33] [I] Save engine: /nvdli-nano/data/Inference/MODELS/Model_7/mobilenet.trt\n",
      "[02/08/2024-06:22:33] [I] Load engine: \n",
      "[02/08/2024-06:22:33] [I] Profiling verbosity: 0\n",
      "[02/08/2024-06:22:33] [I] Tactic sources: Using default tactic sources\n",
      "[02/08/2024-06:22:33] [I] timingCacheMode: local\n",
      "[02/08/2024-06:22:33] [I] timingCacheFile: \n",
      "[02/08/2024-06:22:33] [I] Input(s)s format: fp32:CHW\n",
      "[02/08/2024-06:22:33] [I] Output(s)s format: fp32:CHW\n",
      "[02/08/2024-06:22:33] [I] Input build shapes: model\n",
      "[02/08/2024-06:22:33] [I] Input calibration shapes: model\n",
      "[02/08/2024-06:22:33] [I] === System Options ===\n",
      "[02/08/2024-06:22:33] [I] Device: 0\n",
      "[02/08/2024-06:22:33] [I] DLACore: \n",
      "[02/08/2024-06:22:33] [I] Plugins:\n",
      "[02/08/2024-06:22:33] [I] === Inference Options ===\n",
      "[02/08/2024-06:22:33] [I] Batch: Explicit\n",
      "[02/08/2024-06:22:33] [I] Input inference shapes: model\n",
      "[02/08/2024-06:22:33] [I] Iterations: 10\n",
      "[02/08/2024-06:22:33] [I] Duration: 3s (+ 200ms warm up)\n",
      "[02/08/2024-06:22:33] [I] Sleep time: 0ms\n",
      "[02/08/2024-06:22:33] [I] Idle time: 0ms\n",
      "[02/08/2024-06:22:33] [I] Streams: 1\n",
      "[02/08/2024-06:22:33] [I] ExposeDMA: Disabled\n",
      "[02/08/2024-06:22:33] [I] Data transfers: Enabled\n",
      "[02/08/2024-06:22:33] [I] Spin-wait: Disabled\n",
      "[02/08/2024-06:22:33] [I] Multithreading: Disabled\n",
      "[02/08/2024-06:22:33] [I] CUDA Graph: Disabled\n",
      "[02/08/2024-06:22:33] [I] Separate profiling: Disabled\n",
      "[02/08/2024-06:22:33] [I] Time Deserialize: Disabled\n",
      "[02/08/2024-06:22:33] [I] Time Refit: Disabled\n",
      "[02/08/2024-06:22:33] [I] Skip inference: Disabled\n",
      "[02/08/2024-06:22:33] [I] Inputs:\n",
      "[02/08/2024-06:22:33] [I] === Reporting Options ===\n",
      "[02/08/2024-06:22:33] [I] Verbose: Disabled\n",
      "[02/08/2024-06:22:33] [I] Averages: 10 inferences\n",
      "[02/08/2024-06:22:33] [I] Percentile: 99\n",
      "[02/08/2024-06:22:33] [I] Dump refittable layers:Disabled\n",
      "[02/08/2024-06:22:33] [I] Dump output: Disabled\n",
      "[02/08/2024-06:22:33] [I] Profile: Disabled\n",
      "[02/08/2024-06:22:33] [I] Export timing to JSON file: \n",
      "[02/08/2024-06:22:33] [I] Export output to JSON file: \n",
      "[02/08/2024-06:22:33] [I] Export profile to JSON file: \n",
      "[02/08/2024-06:22:33] [I] \n",
      "[02/08/2024-06:22:33] [I] === Device Information ===\n",
      "[02/08/2024-06:22:33] [I] Selected Device: NVIDIA Tegra X1\n",
      "[02/08/2024-06:22:33] [I] Compute Capability: 5.3\n",
      "[02/08/2024-06:22:33] [I] SMs: 1\n",
      "[02/08/2024-06:22:33] [I] Compute Clock Rate: 0.9216 GHz\n",
      "[02/08/2024-06:22:33] [I] Device Global Memory: 3956 MiB\n",
      "[02/08/2024-06:22:33] [I] Shared Memory per SM: 64 KiB\n",
      "[02/08/2024-06:22:33] [I] Memory Bus Width: 64 bits (ECC disabled)\n",
      "[02/08/2024-06:22:33] [I] Memory Clock Rate: 0.01275 GHz\n",
      "[02/08/2024-06:22:33] [I] \n",
      "[02/08/2024-06:22:33] [I] TensorRT version: 8.2.1\n",
      "[02/08/2024-06:22:53] [I] [TRT] [MemUsageChange] Init CUDA: CPU +229, GPU +19, now: CPU 248, GPU 3904 (MiB)\n",
      "[02/08/2024-06:23:04] [I] [TRT] [MemUsageSnapshot] Begin constructing builder kernel library: CPU 248 MiB, GPU 3883 MiB\n",
      "[02/08/2024-06:23:06] [I] [TRT] [MemUsageSnapshot] End constructing builder kernel library: CPU 278 MiB, GPU 3904 MiB\n",
      "[02/08/2024-06:23:06] [I] Start parsing network model\n",
      "[02/08/2024-06:23:09] [I] [TRT] ----------------------------------------------------------------\n",
      "[02/08/2024-06:23:09] [I] [TRT] Input filename:   /nvdli-nano/data/Inference/MODELS/Model_7/mobilenet.onnx\n",
      "[02/08/2024-06:23:09] [I] [TRT] ONNX IR version:  0.0.7\n",
      "[02/08/2024-06:23:09] [I] [TRT] Opset version:    9\n",
      "[02/08/2024-06:23:09] [I] [TRT] Producer name:    pytorch\n",
      "[02/08/2024-06:23:09] [I] [TRT] Producer version: 1.10\n",
      "[02/08/2024-06:23:09] [I] [TRT] Domain:           \n",
      "[02/08/2024-06:23:09] [I] [TRT] Model version:    0\n",
      "[02/08/2024-06:23:09] [I] [TRT] Doc string:       \n",
      "[02/08/2024-06:23:09] [I] [TRT] ----------------------------------------------------------------\n",
      "[02/08/2024-06:23:13] [I] Finish parsing network model\n",
      "[02/08/2024-06:23:14] [I] [TRT] ---------- Layers Running on DLA ----------\n",
      "[02/08/2024-06:23:14] [I] [TRT] ---------- Layers Running on GPU ----------\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_0 + PWN(Clip_1)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_2 + PWN(Clip_3)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_4\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_5 + PWN(Clip_6)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_7 + PWN(Clip_8)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_9\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_10 + PWN(Clip_11)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_12 + PWN(Clip_13)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_14 + Add_15\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_16 + PWN(Clip_17)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_18 + PWN(Clip_19)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_20\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_21 + PWN(Clip_22)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_23 + PWN(Clip_24)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_25 + Add_26\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_27 + PWN(Clip_28)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_29 + PWN(Clip_30)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_31 + Add_32\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_33 + PWN(Clip_34)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_35 + PWN(Clip_36)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_37\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_38 + PWN(Clip_39)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_40 + PWN(Clip_41)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_42 + Add_43\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_44 + PWN(Clip_45)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_46 + PWN(Clip_47)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_48 + Add_49\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_50 + PWN(Clip_51)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_52 + PWN(Clip_53)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_54 + Add_55\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_56 + PWN(Clip_57)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_58 + PWN(Clip_59)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_60\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_61 + PWN(Clip_62)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_63 + PWN(Clip_64)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_65 + Add_66\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_67 + PWN(Clip_68)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_69 + PWN(Clip_70)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_71 + Add_72\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_73 + PWN(Clip_74)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_75 + PWN(Clip_76)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_77\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_78 + PWN(Clip_79)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_80 + PWN(Clip_81)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_82 + Add_83\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_84 + PWN(Clip_85)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_86 + PWN(Clip_87)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_88 + Add_89\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_90 + PWN(Clip_91)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_92 + PWN(Clip_93)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_94\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Conv_95 + PWN(Clip_96)\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] GlobalAveragePool_97\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] Gemm_99\n",
      "[02/08/2024-06:23:14] [I] [TRT] [GpuLayer] (Unnamed Layer* 101) [Shuffle]\n",
      "[02/08/2024-06:23:42] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +158, GPU +18, now: CPU 450, GPU 3898 (MiB)\n",
      "[02/08/2024-06:24:12] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +241, GPU +3, now: CPU 691, GPU 3904 (MiB)\n",
      "[02/08/2024-06:24:19] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[02/08/2024-06:25:43] [I] [TRT] Some tactics do not have sufficient workspace memory to run. Increasing workspace size may increase performance, please check verbose output.\n",
      "[02/08/2024-06:28:15] [I] [TRT] Detected 1 inputs and 1 output network tensors.\n",
      "[02/08/2024-06:28:15] [I] [TRT] Total Host Persistent Memory: 105584\n",
      "[02/08/2024-06:28:15] [I] [TRT] Total Device Persistent Memory: 7301120\n",
      "[02/08/2024-06:28:15] [I] [TRT] Total Scratch Memory: 5120\n",
      "[02/08/2024-06:28:15] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 8 MiB, GPU 32 MiB\n",
      "[02/08/2024-06:28:15] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 33.4933ms to assign 4 blocks to 55 nodes requiring 7024640 bytes.\n",
      "[02/08/2024-06:28:15] [I] [TRT] Total Activation Memory: 7024640\n",
      "[02/08/2024-06:28:16] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 939, GPU 3863 (MiB)\n",
      "[02/08/2024-06:28:16] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 939, GPU 3871 (MiB)\n",
      "[02/08/2024-06:28:16] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +16, now: CPU 0, GPU 16 (MiB)\n",
      "[02/08/2024-06:28:16] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 952, GPU 3882 (MiB)\n",
      "[02/08/2024-06:28:16] [I] [TRT] Loaded engine size: 13 MiB\n",
      "[02/08/2024-06:28:16] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +1, GPU +1, now: CPU 953, GPU 3884 (MiB)\n",
      "[02/08/2024-06:28:16] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +1, now: CPU 953, GPU 3885 (MiB)\n",
      "[02/08/2024-06:28:16] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +13, now: CPU 0, GPU 13 (MiB)\n",
      "[02/08/2024-06:28:17] [I] Engine built in 343.69 sec.\n",
      "[02/08/2024-06:28:17] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +1, now: CPU 895, GPU 3858 (MiB)\n",
      "[02/08/2024-06:28:17] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +1, now: CPU 895, GPU 3859 (MiB)\n",
      "[02/08/2024-06:28:17] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +14, now: CPU 0, GPU 27 (MiB)\n",
      "[02/08/2024-06:28:17] [I] Using random values for input input.1\n",
      "[02/08/2024-06:28:17] [I] Created input binding for input.1 with dimensions 1x3x224x224\n",
      "[02/08/2024-06:28:17] [I] Using random values for output 466\n",
      "[02/08/2024-06:28:17] [I] Created output binding for 466 with dimensions 1x1000\n",
      "[02/08/2024-06:28:17] [I] Starting inference\n",
      "[02/08/2024-06:28:20] [I] Warmup completed 4 queries over 200 ms\n",
      "[02/08/2024-06:28:20] [I] Timing trace has 144 queries over 3.03658 s\n",
      "[02/08/2024-06:28:20] [I] \n",
      "[02/08/2024-06:28:20] [I] === Trace details ===\n",
      "[02/08/2024-06:28:20] [I] Trace averages of 10 runs:\n",
      "[02/08/2024-06:28:20] [I] Average on 10 runs - GPU latency: 17.202 ms - Host latency: 17.2634 ms (end to end 17.2745 ms, enqueue 4.50939 ms)\n",
      "[02/08/2024-06:28:20] [I] Average on 10 runs - GPU latency: 16.8631 ms - Host latency: 16.9238 ms (end to end 16.9429 ms, enqueue 4.90733 ms)\n",
      "[02/08/2024-06:28:20] [I] Average on 10 runs - GPU latency: 16.6577 ms - Host latency: 16.7179 ms (end to end 16.7278 ms, enqueue 5.33967 ms)\n",
      "[02/08/2024-06:28:20] [I] Average on 10 runs - GPU latency: 16.1384 ms - Host latency: 16.1988 ms (end to end 16.2088 ms, enqueue 4.66358 ms)\n",
      "[02/08/2024-06:28:20] [I] Average on 10 runs - GPU latency: 15.6382 ms - Host latency: 15.6985 ms (end to end 15.7084 ms, enqueue 5.3624 ms)\n",
      "[02/08/2024-06:28:20] [I] Average on 10 runs - GPU latency: 16.6089 ms - Host latency: 16.6782 ms (end to end 16.6884 ms, enqueue 5.30729 ms)\n",
      "[02/08/2024-06:28:20] [I] Average on 10 runs - GPU latency: 19.6868 ms - Host latency: 19.7494 ms (end to end 19.7694 ms, enqueue 4.44791 ms)\n",
      "[02/08/2024-06:28:20] [I] Average on 10 runs - GPU latency: 26.4767 ms - Host latency: 26.5408 ms (end to end 27.2948 ms, enqueue 5.95754 ms)\n",
      "[02/08/2024-06:28:20] [I] Average on 10 runs - GPU latency: 27.8098 ms - Host latency: 27.8732 ms (end to end 28.9673 ms, enqueue 4.88748 ms)\n",
      "[02/08/2024-06:28:20] [I] Average on 10 runs - GPU latency: 25.352 ms - Host latency: 25.4149 ms (end to end 26.1839 ms, enqueue 4.87134 ms)\n",
      "[02/08/2024-06:28:20] [I] Average on 10 runs - GPU latency: 23.488 ms - Host latency: 23.5514 ms (end to end 24.061 ms, enqueue 4.15359 ms)\n",
      "[02/08/2024-06:28:20] [I] Average on 10 runs - GPU latency: 21.3141 ms - Host latency: 21.3775 ms (end to end 21.417 ms, enqueue 4.34473 ms)\n",
      "[02/08/2024-06:28:20] [I] Average on 10 runs - GPU latency: 22.576 ms - Host latency: 22.6401 ms (end to end 22.968 ms, enqueue 4.32068 ms)\n",
      "[02/08/2024-06:28:20] [I] Average on 10 runs - GPU latency: 25.6072 ms - Host latency: 25.671 ms (end to end 25.9492 ms, enqueue 4.68413 ms)\n",
      "[02/08/2024-06:28:20] [I] \n",
      "[02/08/2024-06:28:20] [I] === Performance summary ===\n",
      "[02/08/2024-06:28:20] [I] Throughput: 47.4218 qps\n",
      "[02/08/2024-06:28:20] [I] Latency: min = 14.6431 ms, max = 37.9586 ms, mean = 20.8169 ms, median = 17.6993 ms, percentile(99%) = 34.4207 ms\n",
      "[02/08/2024-06:28:20] [I] End-to-End Host Latency: min = 14.6479 ms, max = 38.1842 ms, mean = 21.0868 ms, median = 17.9226 ms, percentile(99%) = 37.969 ms\n",
      "[02/08/2024-06:28:20] [I] Enqueue Time: min = 3.10132 ms, max = 9.06091 ms, mean = 4.83158 ms, median = 4.79227 ms, percentile(99%) = 8.41333 ms\n",
      "[02/08/2024-06:28:20] [I] H2D Latency: min = 0.0563354 ms, max = 0.140259 ms, mean = 0.0598175 ms, median = 0.0583038 ms, percentile(99%) = 0.0686035 ms\n",
      "[02/08/2024-06:28:20] [I] GPU Compute Time: min = 14.5842 ms, max = 37.8911 ms, mean = 20.754 ms, median = 17.6389 ms, percentile(99%) = 34.3568 ms\n",
      "[02/08/2024-06:28:20] [I] D2H Latency: min = 0.00170898 ms, max = 0.00366211 ms, mean = 0.00303427 ms, median = 0.00305176 ms, percentile(99%) = 0.00366211 ms\n",
      "[02/08/2024-06:28:20] [I] Total Host Walltime: 3.03658 s\n",
      "[02/08/2024-06:28:20] [I] Total GPU Compute Time: 2.98858 s\n",
      "[02/08/2024-06:28:20] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
      "[02/08/2024-06:28:20] [I] \n",
      "&&&& PASSED TensorRT.trtexec [TensorRT v8201] # /usr/src/tensorrt/bin/trtexec --onnx=/nvdli-nano/data/Inference/MODELS/Model_7/mobilenet.onnx --saveEngine=/nvdli-nano/data/Inference/MODELS/Model_7/mobilenet.trt\n"
     ]
    }
   ],
   "source": [
    "!/usr/src/tensorrt/bin/trtexec --onnx=/nvdli-nano/data/Inference/MODELS/Model_7/mobilenet.onnx --saveEngine=/nvdli-nano/data/Inference/MODELS/Model_7/mobilenet.trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a54a6b1-1b9f-40af-a4e1-e2149872c0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: dogs\n",
      "Inference time: 0.30036306381225586 seconds\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorrt as trt\n",
    "import time\n",
    "\n",
    "# Load the TensorRT model\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "with open('mobilenet.trt', 'rb') as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "    engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "# Load and preprocess the input image\n",
    "image_path = '1.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.resize(image, (224, 224))\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "image = image.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
    "image = np.transpose(image, (2, 0, 1))  # Change to channel-first format\n",
    "\n",
    "# Convert to torch tensor\n",
    "image_tensor = torch.tensor(image, dtype=torch.float32)\n",
    "\n",
    "# Run inference and measure time\n",
    "with torch.no_grad():\n",
    "    # Convert the tensor to a batched format\n",
    "    input_data = image_tensor.unsqueeze(0)\n",
    "\n",
    "    # Transfer the input tensor to GPU (if available)\n",
    "    if torch.cuda.is_available():\n",
    "        input_data = input_data.to('cuda')\n",
    "\n",
    "    # Allocate device memory for the input tensor\n",
    "    d_input = torch.cuda.FloatTensor(input_data)\n",
    "\n",
    "    # Allocate device memory for the output tensor\n",
    "    d_output = torch.empty((1, 2), device='cuda')  # Assuming 2 classes (dogs and cats)\n",
    "\n",
    "    # Measure inference time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Run inference\n",
    "    context.execute(1, bindings=[int(d_input.data_ptr()), int(d_output.data_ptr())])\n",
    "\n",
    "    # Measure elapsed time\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    # Transfer the output tensor back to the host\n",
    "    h_output = d_output.cpu().numpy()\n",
    "\n",
    "# Post-process the output\n",
    "predictions = torch.from_numpy(h_output).cpu().numpy()\n",
    "\n",
    "# Assuming the first class corresponds to 'cats' and the second to 'dogs'\n",
    "class_names = ['cats', 'dogs']\n",
    "predicted_class = np.argmax(predictions)\n",
    "\n",
    "# Print the predicted class and inference time\n",
    "print(\"Predicted class:\", class_names[predicted_class])\n",
    "print(\"Inference time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "967215a1-f879-425e-8fb0-d7c2e07ccfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total FLOPs: 150356480\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load the pretrained MobileNet model\n",
    "model = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "# Define input size (224x224x3) for MobileNet\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "# Function to calculate FLOPs for the model\n",
    "def count_flops(model, input_size):\n",
    "    # Define a tensor of appropriate size\n",
    "    input_tensor = torch.randn(1, *input_size)\n",
    "    \n",
    "    # Switch to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Move model to appropriate device\n",
    "    device = next(model.parameters()).device\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Iterate through model's layers\n",
    "    flops = 0\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            # For convolutional layers\n",
    "            output_size = (input_size[0] - module.kernel_size[0] + 2 * module.padding[0]) // module.stride[0] + 1\n",
    "            output_size = (output_size - module.kernel_size[1] + 2 * module.padding[1]) // module.stride[1] + 1\n",
    "            flops += module.in_channels * module.out_channels * module.kernel_size[0] * module.kernel_size[1] * output_size * output_size\n",
    "            input_size = (output_size, output_size, module.out_channels)\n",
    "        elif isinstance(module, torch.nn.Linear):\n",
    "            # For fully connected layers\n",
    "            flops += module.in_features * module.out_features\n",
    "            input_size = (module.out_features,)\n",
    "    \n",
    "    return flops\n",
    "\n",
    "# Calculate FLOPs\n",
    "total_flops = count_flops(model, input_size)\n",
    "print(\"Total FLOPs:\", total_flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68493329-b2a6-4c6c-9a3c-0970efca091e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 3504872\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total trainable parameters: {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e3f881-5bee-42c0-9534-ae6ea35e3dda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
