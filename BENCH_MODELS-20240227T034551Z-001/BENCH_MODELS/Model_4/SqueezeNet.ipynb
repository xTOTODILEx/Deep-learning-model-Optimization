{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "729456b5-4b11-4dc7-a9ee-17cdcd640656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# Load the pre-trained SqueezeNet model\n",
    "model = models.squeezenet1_1(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee5cc61c-f93a-4536-8df4-f2109a2f8bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SqueezeNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (3): Fire(\n",
      "      (squeeze): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Fire(\n",
      "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (6): Fire(\n",
      "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Fire(\n",
      "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (9): Fire(\n",
      "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Fire(\n",
      "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Fire(\n",
      "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Fire(\n",
      "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace=True)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace=True)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24d7262d-f5af-4894-8661-5335cd8fce71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Dogs\n",
      "Inference time: 0.7966 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.models import squeezenet1_1\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "# Load the pre-trained SqueezeNet model\n",
    "model = squeezenet1_1(pretrained=True)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Load and preprocess an example image\n",
    "image_path = '1.jpg'\n",
    "input_image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "# Define the image transformation pipeline\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Apply transformations to the input image\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)  # Add a batch dimension\n",
    "\n",
    "# Make the prediction\n",
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    output = model(input_batch)\n",
    "    end_time = time.time()\n",
    "\n",
    "# Get the predicted class index\n",
    "_, predicted_idx = torch.max(output, 1)\n",
    "predicted_class = \"Cats\" if predicted_idx.item() == 0 else \"Dogs\"\n",
    "\n",
    "# Print the predicted class label and inference time\n",
    "inference_time = end_time - start_time\n",
    "print(f'Predicted class: {predicted_class}')\n",
    "print(f'Inference time: {inference_time:.4f} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad5a82ef-8aee-4374-9064-0428a1aa6c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 1235496\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total trainable parameters: {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d597219-f33a-4812-9f33-b0ea24264779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total FLOPs: 78414144\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Load the pre-trained SqueezeNet model\n",
    "model = models.squeezenet1_1(pretrained=True)\n",
    "\n",
    "# Define input size (224x224x3) for SqueezeNet\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "# Function to calculate FLOPs for the model\n",
    "def count_flops(model, input_size):\n",
    "    # Define a tensor of appropriate size\n",
    "    input_tensor = torch.randn(1, *input_size)\n",
    "    \n",
    "    # Switch to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Move model to appropriate device\n",
    "    device = next(model.parameters()).device\n",
    "    input_tensor = input_tensor.to(device)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Iterate through model's layers\n",
    "    flops = 0\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            # For convolutional layers\n",
    "            output_size = (input_size[0] - module.kernel_size[0] + 2 * module.padding[0]) // module.stride[0] + 1\n",
    "            output_size = (output_size - module.kernel_size[1] + 2 * module.padding[1]) // module.stride[1] + 1\n",
    "            flops += module.in_channels * module.out_channels * module.kernel_size[0] * module.kernel_size[1] * output_size * output_size\n",
    "            input_size = (output_size, output_size, module.out_channels)\n",
    "        elif isinstance(module, torch.nn.MaxPool2d):\n",
    "            # For max pooling layers\n",
    "            output_size = (input_size[0] - module.kernel_size) // module.stride + 1\n",
    "            flops += input_size[2] * output_size * output_size\n",
    "            input_size = (output_size, output_size, input_size[2])\n",
    "        elif isinstance(module, torch.nn.Linear):\n",
    "            # For fully connected layers\n",
    "            flops += module.in_features * module.out_features\n",
    "            input_size = (module.out_features,)\n",
    "    \n",
    "    return flops\n",
    "\n",
    "# Calculate FLOPs\n",
    "total_flops = count_flops(model, input_size)\n",
    "print(\"Total FLOPs:\", total_flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6ecb5b2-94e6-435d-aafc-77c2513c7639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input.1 : Float(1, 3, 224, 224, strides=[150528, 50176, 224, 1], requires_grad=0, device=cpu),\n",
      "      %features.0.weight : Float(64, 3, 3, 3, strides=[27, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.0.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.3.squeeze.weight : Float(16, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.3.squeeze.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.3.expand1x1.weight : Float(64, 16, 1, 1, strides=[16, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.3.expand1x1.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.3.expand3x3.weight : Float(64, 16, 3, 3, strides=[144, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.3.expand3x3.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.4.squeeze.weight : Float(16, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.4.squeeze.bias : Float(16, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.4.expand1x1.weight : Float(64, 16, 1, 1, strides=[16, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.4.expand1x1.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.4.expand3x3.weight : Float(64, 16, 3, 3, strides=[144, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.4.expand3x3.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.6.squeeze.weight : Float(32, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.6.squeeze.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.6.expand1x1.weight : Float(128, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.6.expand1x1.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.6.expand3x3.weight : Float(128, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.6.expand3x3.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.7.squeeze.weight : Float(32, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.7.squeeze.bias : Float(32, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.7.expand1x1.weight : Float(128, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.7.expand1x1.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.7.expand3x3.weight : Float(128, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.7.expand3x3.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.9.squeeze.weight : Float(48, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.9.squeeze.bias : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.9.expand1x1.weight : Float(192, 48, 1, 1, strides=[48, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.9.expand1x1.bias : Float(192, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.9.expand3x3.weight : Float(192, 48, 3, 3, strides=[432, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.9.expand3x3.bias : Float(192, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.10.squeeze.weight : Float(48, 384, 1, 1, strides=[384, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.10.squeeze.bias : Float(48, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.10.expand1x1.weight : Float(192, 48, 1, 1, strides=[48, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.10.expand1x1.bias : Float(192, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.10.expand3x3.weight : Float(192, 48, 3, 3, strides=[432, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.10.expand3x3.bias : Float(192, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.11.squeeze.weight : Float(64, 384, 1, 1, strides=[384, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.11.squeeze.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.11.expand1x1.weight : Float(256, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.11.expand1x1.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.11.expand3x3.weight : Float(256, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.11.expand3x3.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.12.squeeze.weight : Float(64, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.12.squeeze.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.12.expand1x1.weight : Float(256, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %features.12.expand1x1.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.12.expand3x3.weight : Float(256, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.12.expand3x3.bias : Float(256, strides=[1], requires_grad=1, device=cpu),\n",
      "      %classifier.1.weight : Float(1000, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cpu),\n",
      "      %classifier.1.bias : Float(1000, strides=[1], requires_grad=1, device=cpu)):\n",
      "  %53 : Float(1, 64, 111, 111, strides=[788544, 12321, 111, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%input.1, %features.0.weight, %features.0.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %54 : Float(1, 64, 111, 111, strides=[788544, 12321, 111, 1], requires_grad=1, device=cpu) = onnx::Relu(%53) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %55 : Float(1, 64, 55, 55, strides=[193600, 3025, 55, 1], requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 1, 1], strides=[2, 2]](%54) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:719:0\n",
      "  %56 : Float(1, 16, 55, 55, strides=[48400, 3025, 55, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%55, %features.3.squeeze.weight, %features.3.squeeze.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %57 : Float(1, 16, 55, 55, strides=[48400, 3025, 55, 1], requires_grad=1, device=cpu) = onnx::Relu(%56) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %58 : Float(1, 64, 55, 55, strides=[193600, 3025, 55, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%57, %features.3.expand1x1.weight, %features.3.expand1x1.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %59 : Float(1, 64, 55, 55, strides=[193600, 3025, 55, 1], requires_grad=1, device=cpu) = onnx::Relu(%58) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %60 : Float(1, 64, 55, 55, strides=[193600, 3025, 55, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%57, %features.3.expand3x3.weight, %features.3.expand3x3.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %61 : Float(1, 64, 55, 55, strides=[193600, 3025, 55, 1], requires_grad=1, device=cpu) = onnx::Relu(%60) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %62 : Float(1, 128, 55, 55, strides=[387200, 3025, 55, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%59, %61) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/squeezenet.py:40:0\n",
      "  %63 : Float(1, 16, 55, 55, strides=[48400, 3025, 55, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%62, %features.4.squeeze.weight, %features.4.squeeze.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %64 : Float(1, 16, 55, 55, strides=[48400, 3025, 55, 1], requires_grad=1, device=cpu) = onnx::Relu(%63) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %65 : Float(1, 64, 55, 55, strides=[193600, 3025, 55, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%64, %features.4.expand1x1.weight, %features.4.expand1x1.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %66 : Float(1, 64, 55, 55, strides=[193600, 3025, 55, 1], requires_grad=1, device=cpu) = onnx::Relu(%65) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %67 : Float(1, 64, 55, 55, strides=[193600, 3025, 55, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%64, %features.4.expand3x3.weight, %features.4.expand3x3.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %68 : Float(1, 64, 55, 55, strides=[193600, 3025, 55, 1], requires_grad=1, device=cpu) = onnx::Relu(%67) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %69 : Float(1, 128, 55, 55, strides=[387200, 3025, 55, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%66, %68) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/squeezenet.py:40:0\n",
      "  %70 : Float(1, 128, 27, 27, strides=[93312, 729, 27, 1], requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 1, 1], strides=[2, 2]](%69) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:719:0\n",
      "  %71 : Float(1, 32, 27, 27, strides=[23328, 729, 27, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%70, %features.6.squeeze.weight, %features.6.squeeze.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %72 : Float(1, 32, 27, 27, strides=[23328, 729, 27, 1], requires_grad=1, device=cpu) = onnx::Relu(%71) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %73 : Float(1, 128, 27, 27, strides=[93312, 729, 27, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%72, %features.6.expand1x1.weight, %features.6.expand1x1.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %74 : Float(1, 128, 27, 27, strides=[93312, 729, 27, 1], requires_grad=1, device=cpu) = onnx::Relu(%73) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %75 : Float(1, 128, 27, 27, strides=[93312, 729, 27, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%72, %features.6.expand3x3.weight, %features.6.expand3x3.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %76 : Float(1, 128, 27, 27, strides=[93312, 729, 27, 1], requires_grad=1, device=cpu) = onnx::Relu(%75) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %77 : Float(1, 256, 27, 27, strides=[186624, 729, 27, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%74, %76) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/squeezenet.py:40:0\n",
      "  %78 : Float(1, 32, 27, 27, strides=[23328, 729, 27, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%77, %features.7.squeeze.weight, %features.7.squeeze.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %79 : Float(1, 32, 27, 27, strides=[23328, 729, 27, 1], requires_grad=1, device=cpu) = onnx::Relu(%78) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %80 : Float(1, 128, 27, 27, strides=[93312, 729, 27, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%79, %features.7.expand1x1.weight, %features.7.expand1x1.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %81 : Float(1, 128, 27, 27, strides=[93312, 729, 27, 1], requires_grad=1, device=cpu) = onnx::Relu(%80) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %82 : Float(1, 128, 27, 27, strides=[93312, 729, 27, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%79, %features.7.expand3x3.weight, %features.7.expand3x3.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %83 : Float(1, 128, 27, 27, strides=[93312, 729, 27, 1], requires_grad=1, device=cpu) = onnx::Relu(%82) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %84 : Float(1, 256, 27, 27, strides=[186624, 729, 27, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%81, %83) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/squeezenet.py:40:0\n",
      "  %85 : Float(1, 256, 13, 13, strides=[43264, 169, 13, 1], requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 1, 1], strides=[2, 2]](%84) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:719:0\n",
      "  %86 : Float(1, 48, 13, 13, strides=[8112, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%85, %features.9.squeeze.weight, %features.9.squeeze.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %87 : Float(1, 48, 13, 13, strides=[8112, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Relu(%86) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %88 : Float(1, 192, 13, 13, strides=[32448, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%87, %features.9.expand1x1.weight, %features.9.expand1x1.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %89 : Float(1, 192, 13, 13, strides=[32448, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Relu(%88) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %90 : Float(1, 192, 13, 13, strides=[32448, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%87, %features.9.expand3x3.weight, %features.9.expand3x3.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %91 : Float(1, 192, 13, 13, strides=[32448, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Relu(%90) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %92 : Float(1, 384, 13, 13, strides=[64896, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%89, %91) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/squeezenet.py:40:0\n",
      "  %93 : Float(1, 48, 13, 13, strides=[8112, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%92, %features.10.squeeze.weight, %features.10.squeeze.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %94 : Float(1, 48, 13, 13, strides=[8112, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Relu(%93) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %95 : Float(1, 192, 13, 13, strides=[32448, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%94, %features.10.expand1x1.weight, %features.10.expand1x1.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %96 : Float(1, 192, 13, 13, strides=[32448, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Relu(%95) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %97 : Float(1, 192, 13, 13, strides=[32448, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%94, %features.10.expand3x3.weight, %features.10.expand3x3.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %98 : Float(1, 192, 13, 13, strides=[32448, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Relu(%97) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %99 : Float(1, 384, 13, 13, strides=[64896, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%96, %98) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/squeezenet.py:40:0\n",
      "  %100 : Float(1, 64, 13, 13, strides=[10816, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%99, %features.11.squeeze.weight, %features.11.squeeze.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %101 : Float(1, 64, 13, 13, strides=[10816, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Relu(%100) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %102 : Float(1, 256, 13, 13, strides=[43264, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%101, %features.11.expand1x1.weight, %features.11.expand1x1.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %103 : Float(1, 256, 13, 13, strides=[43264, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Relu(%102) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %104 : Float(1, 256, 13, 13, strides=[43264, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%101, %features.11.expand3x3.weight, %features.11.expand3x3.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %105 : Float(1, 256, 13, 13, strides=[43264, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Relu(%104) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %106 : Float(1, 512, 13, 13, strides=[86528, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%103, %105) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/squeezenet.py:40:0\n",
      "  %107 : Float(1, 64, 13, 13, strides=[10816, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%106, %features.12.squeeze.weight, %features.12.squeeze.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %108 : Float(1, 64, 13, 13, strides=[10816, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Relu(%107) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %109 : Float(1, 256, 13, 13, strides=[43264, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%108, %features.12.expand1x1.weight, %features.12.expand1x1.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %110 : Float(1, 256, 13, 13, strides=[43264, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Relu(%109) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %111 : Float(1, 256, 13, 13, strides=[43264, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%108, %features.12.expand3x3.weight, %features.12.expand3x3.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %112 : Float(1, 256, 13, 13, strides=[43264, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Relu(%111) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %113 : Float(1, 512, 13, 13, strides=[86528, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%110, %112) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1169:0\n",
      "  %114 : Float(1, 1000, 13, 13, strides=[169000, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%113, %classifier.1.weight, %classifier.1.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:443:0\n",
      "  %115 : Float(1, 1000, 13, 13, strides=[169000, 169, 13, 1], requires_grad=1, device=cpu) = onnx::Relu(%114) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1297:0\n",
      "  %116 : Float(1, 1000, 1, 1, strides=[1000, 1, 1, 1], requires_grad=1, device=cpu) = onnx::GlobalAveragePool(%115) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1131:0\n",
      "  %117 : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Flatten[axis=1](%116) # /usr/local/lib/python3.6/dist-packages/torchvision-0.11.0a0+fa347eb-py3.6-linux-aarch64.egg/torchvision/models/squeezenet.py:112:0\n",
      "  return (%117)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.onnx\n",
    "\n",
    "# Load the pre-trained SqueezeNet model\n",
    "model = models.squeezenet1_1(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Specify the input size\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Convert the PyTorch model to ONNX\n",
    "onnx_path = 'squeezenet.onnx'\n",
    "torch.onnx.export(model, dummy_input, onnx_path, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bef2dce5-61b4-4dcd-a3c9-381b92f7b6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dae4243a-19db-41a0-81f4-b02e7922c241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&& RUNNING TensorRT.trtexec [TensorRT v8201] # /usr/src/tensorrt/bin/trtexec --onnx=/nvdli-nano/data/Inference/MODELS/Model_4/squeezenet.onnx --saveEngine=/nvdli-nano/data/Inference/MODELS/Model_4/squeezenet.trt\n",
      "[02/08/2024-05:02:52] [I] === Model Options ===\n",
      "[02/08/2024-05:02:52] [I] Format: ONNX\n",
      "[02/08/2024-05:02:52] [I] Model: /nvdli-nano/data/Inference/MODELS/Model_4/squeezenet.onnx\n",
      "[02/08/2024-05:02:52] [I] Output:\n",
      "[02/08/2024-05:02:52] [I] === Build Options ===\n",
      "[02/08/2024-05:02:52] [I] Max batch: explicit batch\n",
      "[02/08/2024-05:02:52] [I] Workspace: 16 MiB\n",
      "[02/08/2024-05:02:52] [I] minTiming: 1\n",
      "[02/08/2024-05:02:52] [I] avgTiming: 8\n",
      "[02/08/2024-05:02:52] [I] Precision: FP32\n",
      "[02/08/2024-05:02:52] [I] Calibration: \n",
      "[02/08/2024-05:02:52] [I] Refit: Disabled\n",
      "[02/08/2024-05:02:52] [I] Sparsity: Disabled\n",
      "[02/08/2024-05:02:52] [I] Safe mode: Disabled\n",
      "[02/08/2024-05:02:52] [I] DirectIO mode: Disabled\n",
      "[02/08/2024-05:02:52] [I] Restricted mode: Disabled\n",
      "[02/08/2024-05:02:52] [I] Save engine: /nvdli-nano/data/Inference/MODELS/Model_4/squeezenet.trt\n",
      "[02/08/2024-05:02:52] [I] Load engine: \n",
      "[02/08/2024-05:02:52] [I] Profiling verbosity: 0\n",
      "[02/08/2024-05:02:52] [I] Tactic sources: Using default tactic sources\n",
      "[02/08/2024-05:02:52] [I] timingCacheMode: local\n",
      "[02/08/2024-05:02:52] [I] timingCacheFile: \n",
      "[02/08/2024-05:02:52] [I] Input(s)s format: fp32:CHW\n",
      "[02/08/2024-05:02:52] [I] Output(s)s format: fp32:CHW\n",
      "[02/08/2024-05:02:52] [I] Input build shapes: model\n",
      "[02/08/2024-05:02:52] [I] Input calibration shapes: model\n",
      "[02/08/2024-05:02:52] [I] === System Options ===\n",
      "[02/08/2024-05:02:52] [I] Device: 0\n",
      "[02/08/2024-05:02:52] [I] DLACore: \n",
      "[02/08/2024-05:02:52] [I] Plugins:\n",
      "[02/08/2024-05:02:52] [I] === Inference Options ===\n",
      "[02/08/2024-05:02:52] [I] Batch: Explicit\n",
      "[02/08/2024-05:02:52] [I] Input inference shapes: model\n",
      "[02/08/2024-05:02:52] [I] Iterations: 10\n",
      "[02/08/2024-05:02:52] [I] Duration: 3s (+ 200ms warm up)\n",
      "[02/08/2024-05:02:52] [I] Sleep time: 0ms\n",
      "[02/08/2024-05:02:52] [I] Idle time: 0ms\n",
      "[02/08/2024-05:02:52] [I] Streams: 1\n",
      "[02/08/2024-05:02:52] [I] ExposeDMA: Disabled\n",
      "[02/08/2024-05:02:52] [I] Data transfers: Enabled\n",
      "[02/08/2024-05:02:52] [I] Spin-wait: Disabled\n",
      "[02/08/2024-05:02:52] [I] Multithreading: Disabled\n",
      "[02/08/2024-05:02:52] [I] CUDA Graph: Disabled\n",
      "[02/08/2024-05:02:52] [I] Separate profiling: Disabled\n",
      "[02/08/2024-05:02:52] [I] Time Deserialize: Disabled\n",
      "[02/08/2024-05:02:52] [I] Time Refit: Disabled\n",
      "[02/08/2024-05:02:52] [I] Skip inference: Disabled\n",
      "[02/08/2024-05:02:52] [I] Inputs:\n",
      "[02/08/2024-05:02:52] [I] === Reporting Options ===\n",
      "[02/08/2024-05:02:52] [I] Verbose: Disabled\n",
      "[02/08/2024-05:02:52] [I] Averages: 10 inferences\n",
      "[02/08/2024-05:02:52] [I] Percentile: 99\n",
      "[02/08/2024-05:02:52] [I] Dump refittable layers:Disabled\n",
      "[02/08/2024-05:02:52] [I] Dump output: Disabled\n",
      "[02/08/2024-05:02:52] [I] Profile: Disabled\n",
      "[02/08/2024-05:02:52] [I] Export timing to JSON file: \n",
      "[02/08/2024-05:02:52] [I] Export output to JSON file: \n",
      "[02/08/2024-05:02:52] [I] Export profile to JSON file: \n",
      "[02/08/2024-05:02:52] [I] \n",
      "[02/08/2024-05:02:52] [I] === Device Information ===\n",
      "[02/08/2024-05:02:52] [I] Selected Device: NVIDIA Tegra X1\n",
      "[02/08/2024-05:02:52] [I] Compute Capability: 5.3\n",
      "[02/08/2024-05:02:52] [I] SMs: 1\n",
      "[02/08/2024-05:02:52] [I] Compute Clock Rate: 0.9216 GHz\n",
      "[02/08/2024-05:02:52] [I] Device Global Memory: 3956 MiB\n",
      "[02/08/2024-05:02:52] [I] Shared Memory per SM: 64 KiB\n",
      "[02/08/2024-05:02:52] [I] Memory Bus Width: 64 bits (ECC disabled)\n",
      "[02/08/2024-05:02:52] [I] Memory Clock Rate: 0.01275 GHz\n",
      "[02/08/2024-05:02:52] [I] \n",
      "[02/08/2024-05:02:52] [I] TensorRT version: 8.2.1\n",
      "[02/08/2024-05:03:03] [I] [TRT] [MemUsageChange] Init CUDA: CPU +229, GPU -22, now: CPU 248, GPU 3882 (MiB)\n",
      "[02/08/2024-05:03:14] [I] [TRT] [MemUsageSnapshot] Begin constructing builder kernel library: CPU 248 MiB, GPU 3889 MiB\n",
      "[02/08/2024-05:03:20] [I] [TRT] [MemUsageSnapshot] End constructing builder kernel library: CPU 277 MiB, GPU 3900 MiB\n",
      "[02/08/2024-05:03:20] [I] Start parsing network model\n",
      "[02/08/2024-05:03:21] [I] [TRT] ----------------------------------------------------------------\n",
      "[02/08/2024-05:03:21] [I] [TRT] Input filename:   /nvdli-nano/data/Inference/MODELS/Model_4/squeezenet.onnx\n",
      "[02/08/2024-05:03:21] [I] [TRT] ONNX IR version:  0.0.7\n",
      "[02/08/2024-05:03:21] [I] [TRT] Opset version:    9\n",
      "[02/08/2024-05:03:21] [I] [TRT] Producer name:    pytorch\n",
      "[02/08/2024-05:03:21] [I] [TRT] Producer version: 1.10\n",
      "[02/08/2024-05:03:21] [I] [TRT] Domain:           \n",
      "[02/08/2024-05:03:21] [I] [TRT] Model version:    0\n",
      "[02/08/2024-05:03:21] [I] [TRT] Doc string:       \n",
      "[02/08/2024-05:03:21] [I] [TRT] ----------------------------------------------------------------\n",
      "[02/08/2024-05:03:22] [I] Finish parsing network model\n",
      "[02/08/2024-05:03:23] [I] [TRT] ---------- Layers Running on DLA ----------\n",
      "[02/08/2024-05:03:23] [I] [TRT] ---------- Layers Running on GPU ----------\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] Conv_0 + Relu_1\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] MaxPool_2\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] Conv_3 + Relu_4\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] Conv_5 + Relu_6\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] Conv_7 + Relu_8\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] Conv_10 + Relu_11\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] Conv_12 + Relu_13\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] Conv_14 + Relu_15\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] MaxPool_17\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] Conv_18 + Relu_19\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] Conv_20 + Relu_21\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] Conv_22 + Relu_23\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] Conv_25 + Relu_26\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] Conv_27 + Relu_28\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] Conv_29 + Relu_30\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] MaxPool_32\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] Conv_33 + Relu_34\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] Conv_35 + Relu_36\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] Conv_37 + Relu_38\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] Conv_40 + Relu_41\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] Conv_42 + Relu_43\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] Conv_44 + Relu_45\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] Conv_47 + Relu_48\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] Conv_49 + Relu_50\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] Conv_51 + Relu_52\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] Conv_54 + Relu_55\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] Conv_56 + Relu_57\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] Conv_58 + Relu_59\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] Conv_61 + Relu_62\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] GlobalAveragePool_63\n",
      "[02/08/2024-05:03:23] [I] [TRT] [GpuLayer] Flatten_64\n",
      "[02/08/2024-05:03:39] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +158, GPU +2, now: CPU 441, GPU 3904 (MiB)\n",
      "[02/08/2024-05:04:24] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +241, GPU -27, now: CPU 682, GPU 3877 (MiB)\n",
      "[02/08/2024-05:04:28] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[02/08/2024-05:05:45] [I] [TRT] Some tactics do not have sufficient workspace memory to run. Increasing workspace size may increase performance, please check verbose output.\n",
      "[02/08/2024-05:06:22] [I] [TRT] Detected 1 inputs and 1 output network tensors.\n",
      "[02/08/2024-05:06:23] [I] [TRT] Total Host Persistent Memory: 62272\n",
      "[02/08/2024-05:06:23] [I] [TRT] Total Device Persistent Memory: 8418816\n",
      "[02/08/2024-05:06:23] [I] [TRT] Total Scratch Memory: 0\n",
      "[02/08/2024-05:06:23] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 2 MiB, GPU 24 MiB\n",
      "[02/08/2024-05:06:23] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 1.07638ms to assign 3 blocks to 22 nodes requiring 4123136 bytes.\n",
      "[02/08/2024-05:06:23] [I] [TRT] Total Activation Memory: 4123136\n",
      "[02/08/2024-05:06:23] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +9, now: CPU 925, GPU 3854 (MiB)\n",
      "[02/08/2024-05:06:23] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +5, now: CPU 925, GPU 3859 (MiB)\n",
      "[02/08/2024-05:06:23] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +0, GPU +16, now: CPU 0, GPU 16 (MiB)\n",
      "[02/08/2024-05:06:23] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 933, GPU 3872 (MiB)\n",
      "[02/08/2024-05:06:23] [I] [TRT] Loaded engine size: 8 MiB\n",
      "[02/08/2024-05:06:23] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 933, GPU 3872 (MiB)\n",
      "[02/08/2024-05:06:23] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +0, now: CPU 933, GPU 3872 (MiB)\n",
      "[02/08/2024-05:06:23] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +8, now: CPU 0, GPU 8 (MiB)\n",
      "[02/08/2024-05:06:23] [I] Engine built in 211.256 sec.\n",
      "[02/08/2024-05:06:23] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 898, GPU 3868 (MiB)\n",
      "[02/08/2024-05:06:23] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +0, now: CPU 898, GPU 3868 (MiB)\n",
      "[02/08/2024-05:06:23] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +11, now: CPU 0, GPU 19 (MiB)\n",
      "[02/08/2024-05:06:23] [I] Using random values for input input.1\n",
      "[02/08/2024-05:06:23] [I] Created input binding for input.1 with dimensions 1x3x224x224\n",
      "[02/08/2024-05:06:23] [I] Using random values for output 117\n",
      "[02/08/2024-05:06:23] [I] Created output binding for 117 with dimensions 1x1000\n",
      "[02/08/2024-05:06:23] [I] Starting inference\n",
      "[02/08/2024-05:06:26] [I] Warmup completed 13 queries over 200 ms\n",
      "[02/08/2024-05:06:26] [I] Timing trace has 317 queries over 3.01851 s\n",
      "[02/08/2024-05:06:26] [I] \n",
      "[02/08/2024-05:06:26] [I] === Trace details ===\n",
      "[02/08/2024-05:06:26] [I] Trace averages of 10 runs:\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 12.0482 ms - Host latency: 12.124 ms (end to end 12.1358 ms, enqueue 2.70467 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 10.7486 ms - Host latency: 10.8288 ms (end to end 10.8695 ms, enqueue 2.12694 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 10.4638 ms - Host latency: 10.5249 ms (end to end 10.5349 ms, enqueue 2.28389 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 11.4454 ms - Host latency: 11.5158 ms (end to end 11.8513 ms, enqueue 2.22156 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 10.1099 ms - Host latency: 10.1796 ms (end to end 10.2002 ms, enqueue 1.93789 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 10.8587 ms - Host latency: 10.9222 ms (end to end 10.9438 ms, enqueue 2.78051 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 8.78878 ms - Host latency: 8.84919 ms (end to end 8.85915 ms, enqueue 1.93418 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 9.09024 ms - Host latency: 9.15032 ms (end to end 9.16111 ms, enqueue 2.33689 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 8.6809 ms - Host latency: 8.74087 ms (end to end 8.75131 ms, enqueue 2.32269 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 8.9593 ms - Host latency: 9.0197 ms (end to end 9.02946 ms, enqueue 2.39742 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 9.36978 ms - Host latency: 9.43254 ms (end to end 9.44412 ms, enqueue 1.78156 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 8.97489 ms - Host latency: 9.03605 ms (end to end 9.04801 ms, enqueue 2.27501 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 10.0199 ms - Host latency: 10.0853 ms (end to end 10.1004 ms, enqueue 2.49393 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 10.2564 ms - Host latency: 10.3311 ms (end to end 10.3409 ms, enqueue 1.86622 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 10.1141 ms - Host latency: 10.1823 ms (end to end 10.2023 ms, enqueue 2.15146 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 9.85598 ms - Host latency: 9.92584 ms (end to end 9.93743 ms, enqueue 2.91428 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 9.52861 ms - Host latency: 9.5979 ms (end to end 9.60981 ms, enqueue 1.72552 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 9.56694 ms - Host latency: 9.62742 ms (end to end 9.6373 ms, enqueue 1.69385 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 9.54539 ms - Host latency: 9.61086 ms (end to end 9.62399 ms, enqueue 2.64864 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 9.68193 ms - Host latency: 9.7427 ms (end to end 9.75247 ms, enqueue 1.75425 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 10.4209 ms - Host latency: 10.4833 ms (end to end 10.497 ms, enqueue 1.8335 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 10.1086 ms - Host latency: 10.1707 ms (end to end 10.1805 ms, enqueue 2.02214 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 9.68728 ms - Host latency: 9.75601 ms (end to end 9.76804 ms, enqueue 1.78687 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 9.21907 ms - Host latency: 9.27939 ms (end to end 9.29109 ms, enqueue 1.91328 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 9.26897 ms - Host latency: 9.33013 ms (end to end 9.35049 ms, enqueue 2.45979 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 7.9093 ms - Host latency: 7.96892 ms (end to end 7.97964 ms, enqueue 1.7813 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 7.70105 ms - Host latency: 7.76096 ms (end to end 7.77075 ms, enqueue 1.6915 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 7.72336 ms - Host latency: 7.78335 ms (end to end 7.7938 ms, enqueue 2.27791 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 7.8865 ms - Host latency: 7.94619 ms (end to end 7.95601 ms, enqueue 2.64854 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 7.72012 ms - Host latency: 7.77949 ms (end to end 7.78948 ms, enqueue 2.42517 ms)\n",
      "[02/08/2024-05:06:26] [I] Average on 10 runs - GPU latency: 7.94001 ms - Host latency: 8.00046 ms (end to end 8.01052 ms, enqueue 2.32424 ms)\n",
      "[02/08/2024-05:06:26] [I] \n",
      "[02/08/2024-05:06:26] [I] === Performance summary ===\n",
      "[02/08/2024-05:06:26] [I] Throughput: 105.019 qps\n",
      "[02/08/2024-05:06:26] [I] Latency: min = 7.53882 ms, max = 16.6945 ms, mean = 9.4981 ms, median = 9.38123 ms, percentile(99%) = 14.3216 ms\n",
      "[02/08/2024-05:06:26] [I] End-to-End Host Latency: min = 7.54932 ms, max = 18.0184 ms, mean = 9.52147 ms, median = 9.3905 ms, percentile(99%) = 14.64 ms\n",
      "[02/08/2024-05:06:26] [I] Enqueue Time: min = 1.3313 ms, max = 12.4351 ms, mean = 2.18274 ms, median = 2.02344 ms, percentile(99%) = 4.41382 ms\n",
      "[02/08/2024-05:06:26] [I] H2D Latency: min = 0.0546875 ms, max = 0.149597 ms, mean = 0.0607346 ms, median = 0.0571289 ms, percentile(99%) = 0.138184 ms\n",
      "[02/08/2024-05:06:26] [I] GPU Compute Time: min = 7.47949 ms, max = 16.631 ms, mean = 9.43391 ms, median = 9.31665 ms, percentile(99%) = 14.2562 ms\n",
      "[02/08/2024-05:06:26] [I] D2H Latency: min = 0.00170898 ms, max = 0.0134277 ms, mean = 0.00345556 ms, median = 0.00317383 ms, percentile(99%) = 0.0125732 ms\n",
      "[02/08/2024-05:06:26] [I] Total Host Walltime: 3.01851 s\n",
      "[02/08/2024-05:06:26] [I] Total GPU Compute Time: 2.99055 s\n",
      "[02/08/2024-05:06:26] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
      "[02/08/2024-05:06:26] [I] \n",
      "&&&& PASSED TensorRT.trtexec [TensorRT v8201] # /usr/src/tensorrt/bin/trtexec --onnx=/nvdli-nano/data/Inference/MODELS/Model_4/squeezenet.onnx --saveEngine=/nvdli-nano/data/Inference/MODELS/Model_4/squeezenet.trt\n"
     ]
    }
   ],
   "source": [
    "!/usr/src/tensorrt/bin/trtexec --onnx=/nvdli-nano/data/Inference/MODELS/Model_4/squeezenet.onnx --saveEngine=/nvdli-nano/data/Inference/MODELS/Model_4/squeezenet.trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "122e4a1b-a100-4db1-bc13-76c17adc9cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: dog\n",
      "Predicted probability: 0.8116484880447388\n",
      "Inference time: 0.16630077362060547 seconds\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorrt as trt\n",
    "import time\n",
    "\n",
    "# Load the TensorRT model\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "with open('squeezenet.trt', 'rb') as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "    engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "# Load and preprocess the input image\n",
    "image_path = '1.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.resize(image, (227, 227))  # Adjust size for SqueezeNet\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "image = image.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
    "image = np.transpose(image, (2, 0, 1))  # Change to channel-first format\n",
    "\n",
    "# Convert to torch tensor\n",
    "image_tensor = torch.tensor(image, dtype=torch.float32)\n",
    "\n",
    "# Run inference and measure time\n",
    "with torch.no_grad():\n",
    "    # Convert the tensor to a batched format\n",
    "    input_data = image_tensor.unsqueeze(0)\n",
    "\n",
    "    # Transfer the input tensor to GPU (if available)\n",
    "    if torch.cuda.is_available():\n",
    "        input_data = input_data.to('cuda')\n",
    "\n",
    "    # Allocate device memory for the input tensor\n",
    "    d_input = torch.cuda.FloatTensor(input_data)\n",
    "\n",
    "    # Allocate device memory for the output tensor\n",
    "    d_output = torch.empty((1, 1), device='cuda')  # Single output neuron for binary classification\n",
    "\n",
    "    # Measure inference time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Run inference\n",
    "    context.execute(1, bindings=[int(d_input.data_ptr()), int(d_output.data_ptr())])\n",
    "\n",
    "    # Measure elapsed time\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    # Transfer the output tensor back to the host\n",
    "    h_output = d_output.cpu().numpy()\n",
    "\n",
    "# Post-process the output\n",
    "predicted_probability = torch.sigmoid(torch.from_numpy(h_output)).item()\n",
    "\n",
    "# Determine the predicted class based on probability threshold (e.g., 0.5)\n",
    "predicted_class = \"dog\" if predicted_probability >= 0.5 else \"cat\"\n",
    "\n",
    "# Print the predicted class and inference time\n",
    "print(\"Predicted class:\", predicted_class)\n",
    "print(\"Predicted probability:\", predicted_probability)\n",
    "print(\"Inference time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238c5c1f-acda-4816-8980-96abedd4bac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
