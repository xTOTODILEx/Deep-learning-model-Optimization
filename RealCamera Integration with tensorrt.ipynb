{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afdce9af-a463-4b0a-b649-7b467c37f74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import ToTensor\n",
    "import time\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import tensorrt as trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cefa959a-0761-437f-a88b-b2afe0d0348a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crw-rw---- 1 root video 81, 0 Dec 21 22:40 /dev/video0\n"
     ]
    }
   ],
   "source": [
    "!ls -ltrh /dev/video*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13322322-d65a-43ce-8487-e1c90f2d7c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetcam.usb_camera import USBCamera\n",
    "\n",
    "#TODO change capture_device if incorrect for your system\n",
    "camera = USBCamera(width=224, height=224, capture_width=640, capture_height=480, capture_device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5778b1d4-6d0f-42f1-99f0-eaf354e98827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa3ea970270436bb9f15ea7d1d79da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7744bb0e264ab1ab8d8a0b654a2b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', disabled=True, layout=Layout(height='100px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import ToTensor\n",
    "import time\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import tensorrt as trt\n",
    "from jetcam.usb_camera import USBCamera\n",
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "from jetcam.utils import bgr8_to_jpeg\n",
    "\n",
    "# Load the TensorRT model\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "with open('conv3D_model_best.trt', 'rb') as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "    engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "# Define the transform for input frames\n",
    "transform = ToTensor()\n",
    "\n",
    "# Constants\n",
    "SEQUENCE_LENGTH = 25\n",
    "IMAGE_HEIGHT = 64\n",
    "IMAGE_WIDTH = 64\n",
    "CLASSES_LIST = [\"WalkingWithDog\", \"TaiChi\", \"Swing\", \"HorseRace\"]\n",
    "\n",
    "\n",
    "# Function to preprocess a single frame\n",
    "def preprocess_frame(frame):\n",
    "    # Convert the image to a NumPy array\n",
    "    frame_np = np.array(frame)\n",
    "\n",
    "    # Resize the frame\n",
    "    resized_frame = cv2.resize(frame_np, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "\n",
    "    # Normalize the frame\n",
    "    normalized_frame = resized_frame / 255.0\n",
    "\n",
    "    return transform(normalized_frame.astype(np.float32))\n",
    "\n",
    "# Function to preprocess a sequence of frames\n",
    "def preprocess_video(frames):\n",
    "    frames = [preprocess_frame(frame) for frame in frames]\n",
    "    frames_tensor = torch.stack(frames)\n",
    "    return frames_tensor.unsqueeze(0)\n",
    "\n",
    "# Create camera object\n",
    "camera = USBCamera(width=224, height=224, capture_width=640, capture_height=480, capture_device=0)\n",
    "image_widget = ipywidgets.Image(format='jpeg')\n",
    "display(image_widget)\n",
    "\n",
    "# Create text widget for live predictions\n",
    "live_prediction_widget = ipywidgets.Textarea(value=\"\", disabled=True, layout={'height': '100px', 'width': '100%'})\n",
    "display(live_prediction_widget)\n",
    "\n",
    "# Capture and preprocess frames in real-time\n",
    "captured_frames = []\n",
    "current_frame_count = 0\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Capture a frame\n",
    "        image = camera.read()\n",
    "\n",
    "        # Display the frame\n",
    "        image_widget.value = bgr8_to_jpeg(image)\n",
    "\n",
    "        # Preprocess the frame\n",
    "        frame = preprocess_frame(image)\n",
    "\n",
    "        # Add the frame to the sequence\n",
    "        captured_frames.append(frame)\n",
    "        current_frame_count += 1\n",
    "\n",
    "        # If we have enough frames, make a prediction\n",
    "        if current_frame_count == SEQUENCE_LENGTH:\n",
    "            # Preprocess the sequence of frames\n",
    "            input_data = preprocess_video(captured_frames)\n",
    "\n",
    "            output_shape = (1, 4)\n",
    "            output = np.empty(output_shape, dtype=np.float32)\n",
    "            # Allocate device memory for inputs and outputs\n",
    "            d_input = cuda.mem_alloc(input_data.element_size() * input_data.nelement())\n",
    "            d_output = cuda.mem_alloc(output.nbytes)\n",
    "\n",
    "            # Create a stream\n",
    "            stream = cuda.Stream()\n",
    "\n",
    "            # Transfer input data to device\n",
    "            cuda.memcpy_htod_async(d_input, input_data.numpy().ravel(), stream)\n",
    "\n",
    "            start_time = time.time()\n",
    "            # Execute inference\n",
    "            context.execute_async(bindings=[int(d_input), int(d_output)], stream_handle=stream.handle)\n",
    "            stream.synchronize()\n",
    "\n",
    "            end_time = time.time()\n",
    "            inference_time = end_time - start_time\n",
    "\n",
    "            # Transfer predictions back to host\n",
    "            cuda.memcpy_dtoh_async(output, d_output, stream)\n",
    "            stream.synchronize()\n",
    "\n",
    "            # Convert the NumPy array to a PyTorch tensor\n",
    "            output_tensor = torch.from_numpy(output)\n",
    "\n",
    "            # Get the predicted class index\n",
    "            _, predicted_class = torch.max(output_tensor, 1)\n",
    "            predicted_class_index = predicted_class.item()\n",
    "\n",
    "            # Map the index to the class name\n",
    "            predicted_class_name = CLASSES_LIST[predicted_class_index]\n",
    "\n",
    "            output_text = f\"Raw Model Output:\\n{output_tensor}\\n\" \\\n",
    "                          f\"Predicted Class Index: {predicted_class_index}\\n\" \\\n",
    "                          f\"Predicted Class Name: {predicted_class_name}\\n\"\\\n",
    "                          f\"Inference Time: {inference_time}\"\n",
    "\n",
    "            live_prediction_widget.value = output_text\n",
    "\n",
    "            # Reset frame count and captured frames\n",
    "            current_frame_count = 0\n",
    "            captured_frames = []\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    # Release the camera\n",
    "    camera.running = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11d3287-85f1-44fa-af90-e2982ff9713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16a7638-1cbc-4269-9a1c-5163eba298a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the size of the serialized engine file\n",
    "model_size = os.path.getsize('/nvdli-nano/data/Inference/conv3D_model.trt')\n",
    "\n",
    "print(f\"The size of the TensorRT model file is: {model_size / (1024 * 1024):.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
